{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 数据工具包\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm,tqdm_notebook \n",
    "## 字符串处理工具包\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing import text, sequence \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import os \n",
    "import gc\n",
    "import joblib\n",
    "from scipy import stats \n",
    "from scipy.sparse import vstack  \n",
    "import time\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import seaborn as sns \n",
    "tqdm.pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dataset.csv')\n",
    "test = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['用户编码', '用户实名制是否通过核实', '用户年龄', '是否大学生客户', '是否黑名单客户', '是否4G不健康客户',\n",
       "       '用户网龄（月）', '用户最近一次缴费距今时长（月）', '缴费用户最近一次缴费金额（元）', '用户近6个月平均消费值（元）',\n",
       "       '用户账单当月总费用（元）', '用户当月账户余额（元）', '缴费用户当前是否欠费缴费', '用户话费敏感度', '当月通话交往圈人数',\n",
       "       '是否经常逛商场的人', '近三个月月均商场出现次数', '当月是否逛过福州仓山万达', '当月是否到过福州山姆会员店', '当月是否看电影',\n",
       "       '当月是否景点游览', '当月是否体育场馆消费', '当月网购类应用使用次数', '当月物流快递类应用使用次数',\n",
       "       '当月金融理财类应用使用总次数', '当月视频播放类应用使用次数', '当月飞机类应用使用次数', '当月火车类应用使用次数',\n",
       "       '当月旅游资讯类应用使用次数', '信用分'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns #30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simple_features(df_):\n",
    "\n",
    "    df = df_.copy() \n",
    "    df['次数'] = df['当月网购类应用使用次数'] +  df['当月物流快递类应用使用次数'] +  df['当月金融理财类应用使用总次数'] + df['当月视频播放类应用使用次数']+ df['当月飞机类应用使用次数'] + df['当月火车类应用使用次数'] + df['当月旅游资讯类应用使用次数']  + 1\n",
    "    for col in ['当月金融理财类应用使用总次数','当月旅游资讯类应用使用次数']: # 这两个比较积极向上一点\n",
    "        df[col + '百分比'] = df[col].values / df['次数'].values \n",
    "    df['当月通话人均话费'] = df['用户账单当月总费用（元）'].values / (df['当月通话交往圈人数'].values + 1)\n",
    "    df['上个月费用'] = df['用户当月账户余额（元）'].values + df['用户账单当月总费用（元）'].values\n",
    "    df['用户上网年龄'] = df['用户年龄'] - df['用户网龄（月）']\n",
    "    df['用户上网年龄百分比'] = df['用户网龄（月）'] / (df['用户年龄'] + 1)\n",
    "    df['近似总消费'] = df['用户近6个月平均消费值（元）'] / 6 * df['用户网龄（月）']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea = _simple_features(train)\n",
    "test_fea  = _simple_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fea.columns) #38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户编码</th>\n",
       "      <th>用户实名制是否通过核实</th>\n",
       "      <th>用户年龄</th>\n",
       "      <th>是否大学生客户</th>\n",
       "      <th>是否黑名单客户</th>\n",
       "      <th>是否4G不健康客户</th>\n",
       "      <th>用户网龄（月）</th>\n",
       "      <th>用户最近一次缴费距今时长（月）</th>\n",
       "      <th>缴费用户最近一次缴费金额（元）</th>\n",
       "      <th>用户近6个月平均消费值（元）</th>\n",
       "      <th>用户账单当月总费用（元）</th>\n",
       "      <th>用户当月账户余额（元）</th>\n",
       "      <th>缴费用户当前是否欠费缴费</th>\n",
       "      <th>用户话费敏感度</th>\n",
       "      <th>当月通话交往圈人数</th>\n",
       "      <th>是否经常逛商场的人</th>\n",
       "      <th>近三个月月均商场出现次数</th>\n",
       "      <th>当月是否逛过福州仓山万达</th>\n",
       "      <th>当月是否到过福州山姆会员店</th>\n",
       "      <th>当月是否看电影</th>\n",
       "      <th>当月是否景点游览</th>\n",
       "      <th>当月是否体育场馆消费</th>\n",
       "      <th>当月网购类应用使用次数</th>\n",
       "      <th>当月物流快递类应用使用次数</th>\n",
       "      <th>当月金融理财类应用使用总次数</th>\n",
       "      <th>当月视频播放类应用使用次数</th>\n",
       "      <th>当月飞机类应用使用次数</th>\n",
       "      <th>当月火车类应用使用次数</th>\n",
       "      <th>当月旅游资讯类应用使用次数</th>\n",
       "      <th>信用分</th>\n",
       "      <th>次数</th>\n",
       "      <th>当月金融理财类应用使用总次数百分比</th>\n",
       "      <th>当月旅游资讯类应用使用次数百分比</th>\n",
       "      <th>当月通话人均话费</th>\n",
       "      <th>上个月费用</th>\n",
       "      <th>用户上网年龄</th>\n",
       "      <th>用户上网年龄百分比</th>\n",
       "      <th>近似总消费</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4651f98c82948b186bdcdc8108381b4</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>99.80</td>\n",
       "      <td>163.86</td>\n",
       "      <td>159.20</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>2740</td>\n",
       "      <td>7145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>664</td>\n",
       "      <td>10629</td>\n",
       "      <td>0.257785</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>1.895238</td>\n",
       "      <td>339.20</td>\n",
       "      <td>-142</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>5079.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aeb10247db4e4d67b2550bbc42ff9827</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29.94</td>\n",
       "      <td>153.28</td>\n",
       "      <td>145.10</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2731</td>\n",
       "      <td>44862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>48008</td>\n",
       "      <td>0.056886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.595455</td>\n",
       "      <td>255.10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>127.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5af23a1e0e77410abb25e9a7eee510aa</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>49.90</td>\n",
       "      <td>109.64</td>\n",
       "      <td>120.20</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>643</td>\n",
       "      <td>8197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>2.003333</td>\n",
       "      <td>190.20</td>\n",
       "      <td>-98</td>\n",
       "      <td>3.020833</td>\n",
       "      <td>2649.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43c64379d3c24a15b8478851b22049e4</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>99.80</td>\n",
       "      <td>92.97</td>\n",
       "      <td>167.42</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1931</td>\n",
       "      <td>3141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>649</td>\n",
       "      <td>5578</td>\n",
       "      <td>0.346181</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>2.119241</td>\n",
       "      <td>257.42</td>\n",
       "      <td>-179</td>\n",
       "      <td>4.178571</td>\n",
       "      <td>3625.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1687f3b8a6f4910bd0b13eb634056e2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>49.90</td>\n",
       "      <td>95.47</td>\n",
       "      <td>101.00</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>646</td>\n",
       "      <td>0.099071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.422535</td>\n",
       "      <td>181.00</td>\n",
       "      <td>-36</td>\n",
       "      <td>1.853659</td>\n",
       "      <td>1209.286667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               用户编码  用户实名制是否通过核实  用户年龄  是否大学生客户  是否黑名单客户  是否4G不健康客户  用户网龄（月）  用户最近一次缴费距今时长（月）  缴费用户最近一次缴费金额（元）  用户近6个月平均消费值（元）  用户账单当月总费用（元）  用户当月账户余额（元）  缴费用户当前是否欠费缴费  用户话费敏感度  当月通话交往圈人数  是否经常逛商场的人  近三个月月均商场出现次数  当月是否逛过福州仓山万达  当月是否到过福州山姆会员店  当月是否看电影  当月是否景点游览  当月是否体育场馆消费  当月网购类应用使用次数  当月物流快递类应用使用次数  当月金融理财类应用使用总次数  当月视频播放类应用使用次数  当月飞机类应用使用次数  当月火车类应用使用次数  当月旅游资讯类应用使用次数  信用分     次数  当月金融理财类应用使用总次数百分比  当月旅游资讯类应用使用次数百分比  当月通话人均话费   上个月费用  用户上网年龄  用户上网年龄百分比        近似总消费\n",
       "0  a4651f98c82948b186bdcdc8108381b4            1    44        0        0          0      186                1            99.80          163.86        159.20          180             0        3         83          1            75             0              0        0         1           1          713              0            2740           7145            0            0             30  664  10629           0.257785          0.002822  1.895238  339.20    -142   4.133333  5079.660000\n",
       "1  aeb10247db4e4d67b2550bbc42ff9827            1    18        0        0          1        5                1            29.94          153.28        145.10          110             0        3         21          1            16             0              0        0         0           0          414              0            2731          44862            0            0              0  530  48008           0.056886          0.000000  6.595455  255.10      13   0.263158   127.733333\n",
       "2  5af23a1e0e77410abb25e9a7eee510aa            1    47        0        0          0      145                1            49.90          109.64        120.20           70             0        1         59          0             1             0              0        0         0           0         3391              0               0           4804            0            0              1  643   8197           0.000000          0.000122  2.003333  190.20     -98   3.020833  2649.633333\n",
       "3  43c64379d3c24a15b8478851b22049e4            1    55        0        0          0      234                1            99.80           92.97        167.42           90             0        3         78          1            26             0              0        0         1           1          500              0            1931           3141            0            0              5  649   5578           0.346181          0.000896  2.119241  257.42    -179   4.178571  3625.830000\n",
       "4  f1687f3b8a6f4910bd0b13eb634056e2            1    40        0        0          0       76                1            49.90           95.47        101.00           80             0        3         70          1            44             0              0        0         1           0          522              0              64             59            0            0              0  648    646           0.099071          0.000000  1.422535  181.00     -36   1.853659  1209.286667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_cols = [col for col in train_fea.columns if train_fea[col].dtypes!='object' and train_fea[col].dtypes != '<M8[ns]' and col!='用户编码' and col!='信用分']  \n",
    "# 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def _get_values_lgbregresser_models(df_fea, df_label,  feature_names):\n",
    "    \n",
    "    kf = KFold(n_splits=5,shuffle=False)#,random_state=1)\n",
    "\n",
    "    models  = []\n",
    "    models_1 = []\n",
    "    models_2 = []\n",
    "    importances = pd.DataFrame() \n",
    "    \n",
    "    lgb_params = {'num_leaves': 31,'min_data_in_leaf': 32, \n",
    "'max_depth': -1, 'learning_rate': 0.005,\"min_child_samples\": 20,\"boosting\": \"gbdt\",\"feature_fraction\": 0.9,\n",
    "\"bagging_freq\": 1,\"bagging_fraction\": 0.9 ,'n_estimators': 10000,\"bagging_seed\": 11,\"metric\": 'rmse',\n",
    "\"lambda_l1\": 0.1,\"nthread\": 50,\"verbosity\": -1}\n",
    "\n",
    "    lgb_params1 = {'num_leaves': 31,'min_data_in_leaf': 32, 'objective':'mae',\n",
    "'max_depth': -1, 'learning_rate': 0.005,\"min_child_samples\": 20,\"boosting\": \"gbdt\",\"feature_fraction\": 0.9,\n",
    "\"bagging_freq\": 1,\"bagging_fraction\": 0.9 ,'n_estimators': 10000,\"bagging_seed\": 11,\n",
    "\"lambda_l1\": 0.1,\"nthread\": 50,\"verbosity\": -1}\n",
    "\n",
    "    min_val = np.min(df_label) #最小的信用分\n",
    "    print(\"训练集中最小的信用分\",min_val)\n",
    "\n",
    "    for fold_, (trn_, val_) in enumerate(kf.split(df_fea)): \n",
    "\n",
    "        trn_x, trn_y= df_fea[trn_,:], df_label[trn_] # 划分出来的训练集的特征和标签\n",
    "        val_x, val_y = df_fea[val_,:], df_label[val_]# \n",
    "        \n",
    "        tmp = pd.DataFrame()\n",
    "\n",
    "        model = lgb.LGBMRegressor(**lgb_params1) #第二种参数\n",
    "        model.fit(trn_x, trn_y, eval_set=[(trn_x, trn_y), (val_x, val_y)], eval_metric ='mae',verbose=50,early_stopping_rounds=250)     \n",
    "        tmp['target'] = val_y #实际的测试集的标签\n",
    "        tmp['pred1'] = model.predict(val_x) #预测的测试集的标签\n",
    "        models.append(model)\n",
    "\n",
    "        \n",
    "        model1 = lgb.LGBMRegressor(**lgb_params) # 第一种参数\n",
    "        model1.fit(trn_x, trn_y, eval_set=[(trn_x, trn_y), (val_x, val_y)], eval_metric ='mae',verbose=50,early_stopping_rounds=250)     \n",
    "        tmp['pred2'] = model1.predict(val_x) #预测的测试集的标签\n",
    "        models_1.append(model1)\n",
    "\n",
    "\n",
    "        tmp = tmp.sort_values('pred1')\n",
    "        tmp['ranks'] = list(range(tmp.shape[0]))\n",
    "        tmp['preds'] = tmp['pred1'].values\n",
    "        #对两种参数预测的结果分别添加对应的权重\n",
    "        tmp.loc[tmp.ranks<2000,'preds']  = tmp.loc[tmp.ranks< 2000,'pred2'].values *0.4 + tmp.loc[tmp.ranks< 2000,'pred1'].values * 0.6\n",
    "        tmp.loc[tmp.ranks>8000,'preds']  = tmp.loc[tmp.ranks> 8000,'pred2'].values *0.4 + tmp.loc[tmp.ranks> 8000,'pred1'].values * 0.6\n",
    "\n",
    "        print('*' * 100)\n",
    "        print('MAE Model',     1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['pred1'] ))))\n",
    "        print('MSE Model',     1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['pred2'] ))))\n",
    "        print('Merge Model12', 1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['preds'] )))) \n",
    "\n",
    "\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = feature_names\n",
    "        imp_df['gain'] = model.feature_importances_\n",
    "        imp_df['fold'] = fold_ + 1\n",
    "\n",
    "        importances = pd.concat([importances, imp_df], axis=0)\n",
    "        gc.collect() \n",
    "    return models,models_1,importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中最小的信用分 422\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's l1: 27.6411\tvalid_1's l1: 27.8676\n",
      "[100]\ttraining's l1: 23.8993\tvalid_1's l1: 24.1131\n",
      "[150]\ttraining's l1: 21.2376\tvalid_1's l1: 21.487\n",
      "[200]\ttraining's l1: 19.3633\tvalid_1's l1: 19.6374\n",
      "[250]\ttraining's l1: 18.044\tvalid_1's l1: 18.3506\n",
      "[300]\ttraining's l1: 17.1245\tvalid_1's l1: 17.4783\n",
      "[350]\ttraining's l1: 16.4794\tvalid_1's l1: 16.8891\n",
      "[400]\ttraining's l1: 16.0182\tvalid_1's l1: 16.471\n",
      "[450]\ttraining's l1: 15.6845\tvalid_1's l1: 16.1732\n",
      "[500]\ttraining's l1: 15.4377\tvalid_1's l1: 15.954\n",
      "[550]\ttraining's l1: 15.2476\tvalid_1's l1: 15.7838\n",
      "[600]\ttraining's l1: 15.0954\tvalid_1's l1: 15.6569\n",
      "[650]\ttraining's l1: 14.9712\tvalid_1's l1: 15.5571\n",
      "[700]\ttraining's l1: 14.8663\tvalid_1's l1: 15.4745\n",
      "[750]\ttraining's l1: 14.7747\tvalid_1's l1: 15.4054\n",
      "[800]\ttraining's l1: 14.6936\tvalid_1's l1: 15.3467\n",
      "[850]\ttraining's l1: 14.6233\tvalid_1's l1: 15.2981\n",
      "[900]\ttraining's l1: 14.5626\tvalid_1's l1: 15.2589\n",
      "[950]\ttraining's l1: 14.506\tvalid_1's l1: 15.2248\n",
      "[1000]\ttraining's l1: 14.4567\tvalid_1's l1: 15.1981\n",
      "[1050]\ttraining's l1: 14.4107\tvalid_1's l1: 15.172\n",
      "[1100]\ttraining's l1: 14.3678\tvalid_1's l1: 15.1499\n",
      "[1150]\ttraining's l1: 14.3271\tvalid_1's l1: 15.1315\n",
      "[1200]\ttraining's l1: 14.2894\tvalid_1's l1: 15.1141\n",
      "[1250]\ttraining's l1: 14.2551\tvalid_1's l1: 15.101\n",
      "[1300]\ttraining's l1: 14.2211\tvalid_1's l1: 15.0882\n",
      "[1350]\ttraining's l1: 14.1906\tvalid_1's l1: 15.0782\n",
      "[1400]\ttraining's l1: 14.1597\tvalid_1's l1: 15.0682\n",
      "[1450]\ttraining's l1: 14.1297\tvalid_1's l1: 15.0589\n",
      "[1500]\ttraining's l1: 14.1015\tvalid_1's l1: 15.0513\n",
      "[1550]\ttraining's l1: 14.0736\tvalid_1's l1: 15.0436\n",
      "[1600]\ttraining's l1: 14.049\tvalid_1's l1: 15.0388\n",
      "[1650]\ttraining's l1: 14.0236\tvalid_1's l1: 15.0336\n",
      "[1700]\ttraining's l1: 13.9991\tvalid_1's l1: 15.0293\n",
      "[1750]\ttraining's l1: 13.9758\tvalid_1's l1: 15.0251\n",
      "[1800]\ttraining's l1: 13.9527\tvalid_1's l1: 15.0208\n",
      "[1850]\ttraining's l1: 13.93\tvalid_1's l1: 15.0177\n",
      "[1900]\ttraining's l1: 13.9075\tvalid_1's l1: 15.0144\n",
      "[1950]\ttraining's l1: 13.885\tvalid_1's l1: 15.0105\n",
      "[2000]\ttraining's l1: 13.8623\tvalid_1's l1: 15.0056\n",
      "[2050]\ttraining's l1: 13.841\tvalid_1's l1: 15.0033\n",
      "[2100]\ttraining's l1: 13.8201\tvalid_1's l1: 14.9999\n",
      "[2150]\ttraining's l1: 13.7986\tvalid_1's l1: 14.996\n",
      "[2200]\ttraining's l1: 13.7766\tvalid_1's l1: 14.9915\n",
      "[2250]\ttraining's l1: 13.7559\tvalid_1's l1: 14.9886\n",
      "[2300]\ttraining's l1: 13.7358\tvalid_1's l1: 14.9861\n",
      "[2350]\ttraining's l1: 13.7146\tvalid_1's l1: 14.9824\n",
      "[2400]\ttraining's l1: 13.6942\tvalid_1's l1: 14.9792\n",
      "[2450]\ttraining's l1: 13.6746\tvalid_1's l1: 14.9772\n",
      "[2500]\ttraining's l1: 13.6558\tvalid_1's l1: 14.9756\n",
      "[2550]\ttraining's l1: 13.6372\tvalid_1's l1: 14.9733\n",
      "[2600]\ttraining's l1: 13.6188\tvalid_1's l1: 14.9717\n",
      "[2650]\ttraining's l1: 13.5999\tvalid_1's l1: 14.9691\n",
      "[2700]\ttraining's l1: 13.5825\tvalid_1's l1: 14.9682\n",
      "[2750]\ttraining's l1: 13.564\tvalid_1's l1: 14.966\n",
      "[2800]\ttraining's l1: 13.5467\tvalid_1's l1: 14.9643\n",
      "[2850]\ttraining's l1: 13.5286\tvalid_1's l1: 14.9626\n",
      "[2900]\ttraining's l1: 13.5103\tvalid_1's l1: 14.9602\n",
      "[2950]\ttraining's l1: 13.4934\tvalid_1's l1: 14.9598\n",
      "[3000]\ttraining's l1: 13.4766\tvalid_1's l1: 14.9582\n",
      "[3050]\ttraining's l1: 13.4598\tvalid_1's l1: 14.9567\n",
      "[3100]\ttraining's l1: 13.4434\tvalid_1's l1: 14.9548\n",
      "[3150]\ttraining's l1: 13.4271\tvalid_1's l1: 14.9536\n",
      "[3200]\ttraining's l1: 13.4103\tvalid_1's l1: 14.9527\n",
      "[3250]\ttraining's l1: 13.3945\tvalid_1's l1: 14.9518\n",
      "[3300]\ttraining's l1: 13.3793\tvalid_1's l1: 14.9512\n",
      "[3350]\ttraining's l1: 13.3628\tvalid_1's l1: 14.9499\n",
      "[3400]\ttraining's l1: 13.3481\tvalid_1's l1: 14.9494\n",
      "[3450]\ttraining's l1: 13.3319\tvalid_1's l1: 14.9479\n",
      "[3500]\ttraining's l1: 13.3164\tvalid_1's l1: 14.9463\n",
      "[3550]\ttraining's l1: 13.3015\tvalid_1's l1: 14.9453\n",
      "[3600]\ttraining's l1: 13.2863\tvalid_1's l1: 14.9443\n",
      "[3650]\ttraining's l1: 13.2718\tvalid_1's l1: 14.9434\n",
      "[3700]\ttraining's l1: 13.2569\tvalid_1's l1: 14.9425\n",
      "[3750]\ttraining's l1: 13.2414\tvalid_1's l1: 14.9415\n",
      "[3800]\ttraining's l1: 13.2266\tvalid_1's l1: 14.9407\n",
      "[3850]\ttraining's l1: 13.2118\tvalid_1's l1: 14.9399\n",
      "[3900]\ttraining's l1: 13.1974\tvalid_1's l1: 14.9392\n",
      "[3950]\ttraining's l1: 13.1819\tvalid_1's l1: 14.9376\n",
      "[4000]\ttraining's l1: 13.1675\tvalid_1's l1: 14.9365\n",
      "[4050]\ttraining's l1: 13.1528\tvalid_1's l1: 14.9356\n",
      "[4100]\ttraining's l1: 13.1379\tvalid_1's l1: 14.9339\n",
      "[4150]\ttraining's l1: 13.1238\tvalid_1's l1: 14.9324\n",
      "[4200]\ttraining's l1: 13.1102\tvalid_1's l1: 14.9317\n",
      "[4250]\ttraining's l1: 13.0966\tvalid_1's l1: 14.9313\n",
      "[4300]\ttraining's l1: 13.0835\tvalid_1's l1: 14.9305\n",
      "[4350]\ttraining's l1: 13.0692\tvalid_1's l1: 14.9287\n",
      "[4400]\ttraining's l1: 13.0549\tvalid_1's l1: 14.9286\n",
      "[4450]\ttraining's l1: 13.0408\tvalid_1's l1: 14.9274\n",
      "[4500]\ttraining's l1: 13.0268\tvalid_1's l1: 14.9268\n",
      "[4550]\ttraining's l1: 13.0135\tvalid_1's l1: 14.9261\n",
      "[4600]\ttraining's l1: 13.0011\tvalid_1's l1: 14.9257\n",
      "[4650]\ttraining's l1: 12.9882\tvalid_1's l1: 14.9253\n",
      "[4700]\ttraining's l1: 12.9752\tvalid_1's l1: 14.9245\n",
      "[4750]\ttraining's l1: 12.9624\tvalid_1's l1: 14.9236\n",
      "[4800]\ttraining's l1: 12.9502\tvalid_1's l1: 14.9232\n",
      "[4850]\ttraining's l1: 12.9372\tvalid_1's l1: 14.9231\n",
      "[4900]\ttraining's l1: 12.9242\tvalid_1's l1: 14.922\n",
      "[4950]\ttraining's l1: 12.9122\tvalid_1's l1: 14.9214\n",
      "[5000]\ttraining's l1: 12.8998\tvalid_1's l1: 14.9207\n",
      "[5050]\ttraining's l1: 12.8878\tvalid_1's l1: 14.9204\n",
      "[5100]\ttraining's l1: 12.8759\tvalid_1's l1: 14.9197\n",
      "[5150]\ttraining's l1: 12.8639\tvalid_1's l1: 14.9192\n",
      "[5200]\ttraining's l1: 12.852\tvalid_1's l1: 14.9185\n",
      "[5250]\ttraining's l1: 12.8398\tvalid_1's l1: 14.918\n",
      "[5300]\ttraining's l1: 12.8275\tvalid_1's l1: 14.9177\n",
      "[5350]\ttraining's l1: 12.8159\tvalid_1's l1: 14.917\n",
      "[5400]\ttraining's l1: 12.8047\tvalid_1's l1: 14.917\n",
      "[5450]\ttraining's l1: 12.7922\tvalid_1's l1: 14.9162\n",
      "[5500]\ttraining's l1: 12.7799\tvalid_1's l1: 14.9157\n",
      "[5550]\ttraining's l1: 12.7685\tvalid_1's l1: 14.9157\n",
      "[5600]\ttraining's l1: 12.7571\tvalid_1's l1: 14.915\n",
      "[5650]\ttraining's l1: 12.7458\tvalid_1's l1: 14.9145\n",
      "[5700]\ttraining's l1: 12.7346\tvalid_1's l1: 14.9144\n",
      "[5750]\ttraining's l1: 12.7231\tvalid_1's l1: 14.9145\n",
      "[5800]\ttraining's l1: 12.7122\tvalid_1's l1: 14.914\n",
      "[5850]\ttraining's l1: 12.7004\tvalid_1's l1: 14.9134\n",
      "[5900]\ttraining's l1: 12.6892\tvalid_1's l1: 14.9138\n",
      "[5950]\ttraining's l1: 12.6777\tvalid_1's l1: 14.9134\n",
      "[6000]\ttraining's l1: 12.6655\tvalid_1's l1: 14.9128\n",
      "[6050]\ttraining's l1: 12.6546\tvalid_1's l1: 14.912\n",
      "[6100]\ttraining's l1: 12.6442\tvalid_1's l1: 14.9117\n",
      "[6150]\ttraining's l1: 12.6339\tvalid_1's l1: 14.9116\n",
      "[6200]\ttraining's l1: 12.6233\tvalid_1's l1: 14.9113\n",
      "[6250]\ttraining's l1: 12.613\tvalid_1's l1: 14.9114\n",
      "[6300]\ttraining's l1: 12.6026\tvalid_1's l1: 14.9113\n",
      "[6350]\ttraining's l1: 12.5921\tvalid_1's l1: 14.9113\n",
      "[6400]\ttraining's l1: 12.5818\tvalid_1's l1: 14.9111\n",
      "[6450]\ttraining's l1: 12.5707\tvalid_1's l1: 14.9105\n",
      "[6500]\ttraining's l1: 12.5611\tvalid_1's l1: 14.9104\n",
      "[6550]\ttraining's l1: 12.5524\tvalid_1's l1: 14.9101\n",
      "[6600]\ttraining's l1: 12.5429\tvalid_1's l1: 14.9099\n",
      "[6650]\ttraining's l1: 12.5333\tvalid_1's l1: 14.9099\n",
      "[6700]\ttraining's l1: 12.5234\tvalid_1's l1: 14.9099\n",
      "[6750]\ttraining's l1: 12.5139\tvalid_1's l1: 14.9099\n",
      "[6800]\ttraining's l1: 12.5044\tvalid_1's l1: 14.9103\n",
      "[6850]\ttraining's l1: 12.4942\tvalid_1's l1: 14.9102\n",
      "Early stopping, best iteration is:\n",
      "[6608]\ttraining's l1: 12.5414\tvalid_1's l1: 14.9097\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's rmse: 35.7565\ttraining's l1: 28.1102\tvalid_1's rmse: 35.9354\tvalid_1's l1: 28.3025\n",
      "[100]\ttraining's rmse: 30.901\ttraining's l1: 24.1224\tvalid_1's rmse: 31.1362\tvalid_1's l1: 24.3483\n",
      "[150]\ttraining's rmse: 27.4511\ttraining's l1: 21.2877\tvalid_1's rmse: 27.7343\tvalid_1's l1: 21.5622\n",
      "[200]\ttraining's rmse: 25.03\ttraining's l1: 19.3155\tvalid_1's rmse: 25.3545\tvalid_1's l1: 19.6073\n",
      "[250]\ttraining's rmse: 23.345\ttraining's l1: 17.9674\tvalid_1's rmse: 23.7101\tvalid_1's l1: 18.2751\n",
      "[300]\ttraining's rmse: 22.1808\ttraining's l1: 17.0478\tvalid_1's rmse: 22.5859\tvalid_1's l1: 17.3838\n",
      "[350]\ttraining's rmse: 21.3707\ttraining's l1: 16.4157\tvalid_1's rmse: 21.8163\tvalid_1's l1: 16.7879\n",
      "[400]\ttraining's rmse: 20.8006\ttraining's l1: 15.9735\tvalid_1's rmse: 21.2797\tvalid_1's l1: 16.3806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\ttraining's rmse: 20.3892\ttraining's l1: 15.6579\tvalid_1's rmse: 20.9007\tvalid_1's l1: 16.097\n",
      "[500]\ttraining's rmse: 20.0806\ttraining's l1: 15.424\tvalid_1's rmse: 20.6193\tvalid_1's l1: 15.8929\n",
      "[550]\ttraining's rmse: 19.8421\ttraining's l1: 15.2476\tvalid_1's rmse: 20.4049\tvalid_1's l1: 15.7394\n",
      "[600]\ttraining's rmse: 19.6546\ttraining's l1: 15.1076\tvalid_1's rmse: 20.2425\tvalid_1's l1: 15.6239\n",
      "[650]\ttraining's rmse: 19.5011\ttraining's l1: 14.9939\tvalid_1's rmse: 20.1135\tvalid_1's l1: 15.5319\n",
      "[700]\ttraining's rmse: 19.3706\ttraining's l1: 14.8979\tvalid_1's rmse: 20.0055\tvalid_1's l1: 15.4554\n",
      "[750]\ttraining's rmse: 19.2571\ttraining's l1: 14.8137\tvalid_1's rmse: 19.9154\tvalid_1's l1: 15.3894\n",
      "[800]\ttraining's rmse: 19.1572\ttraining's l1: 14.7404\tvalid_1's rmse: 19.8412\tvalid_1's l1: 15.336\n",
      "[850]\ttraining's rmse: 19.0666\ttraining's l1: 14.6743\tvalid_1's rmse: 19.7742\tvalid_1's l1: 15.2873\n",
      "[900]\ttraining's rmse: 18.9901\ttraining's l1: 14.6179\tvalid_1's rmse: 19.7207\tvalid_1's l1: 15.25\n",
      "[950]\ttraining's rmse: 18.918\ttraining's l1: 14.5658\tvalid_1's rmse: 19.6737\tvalid_1's l1: 15.2178\n",
      "[1000]\ttraining's rmse: 18.8514\ttraining's l1: 14.517\tvalid_1's rmse: 19.6308\tvalid_1's l1: 15.1888\n",
      "[1050]\ttraining's rmse: 18.7887\ttraining's l1: 14.4712\tvalid_1's rmse: 19.5934\tvalid_1's l1: 15.1633\n",
      "[1100]\ttraining's rmse: 18.7292\ttraining's l1: 14.4289\tvalid_1's rmse: 19.5606\tvalid_1's l1: 15.1412\n",
      "[1150]\ttraining's rmse: 18.6723\ttraining's l1: 14.3879\tvalid_1's rmse: 19.5294\tvalid_1's l1: 15.1194\n",
      "[1200]\ttraining's rmse: 18.6162\ttraining's l1: 14.3482\tvalid_1's rmse: 19.4969\tvalid_1's l1: 15.0967\n",
      "[1250]\ttraining's rmse: 18.5667\ttraining's l1: 14.3133\tvalid_1's rmse: 19.4729\tvalid_1's l1: 15.0806\n",
      "[1300]\ttraining's rmse: 18.5189\ttraining's l1: 14.2792\tvalid_1's rmse: 19.4494\tvalid_1's l1: 15.0651\n",
      "[1350]\ttraining's rmse: 18.4736\ttraining's l1: 14.2472\tvalid_1's rmse: 19.4298\tvalid_1's l1: 15.0516\n",
      "[1400]\ttraining's rmse: 18.4301\ttraining's l1: 14.2166\tvalid_1's rmse: 19.4124\tvalid_1's l1: 15.0405\n",
      "[1450]\ttraining's rmse: 18.3892\ttraining's l1: 14.187\tvalid_1's rmse: 19.3978\tvalid_1's l1: 15.0301\n",
      "[1500]\ttraining's rmse: 18.348\ttraining's l1: 14.1583\tvalid_1's rmse: 19.3818\tvalid_1's l1: 15.0192\n",
      "[1550]\ttraining's rmse: 18.3087\ttraining's l1: 14.1303\tvalid_1's rmse: 19.3679\tvalid_1's l1: 15.01\n",
      "[1600]\ttraining's rmse: 18.2726\ttraining's l1: 14.1047\tvalid_1's rmse: 19.3576\tvalid_1's l1: 15.0031\n",
      "[1650]\ttraining's rmse: 18.2357\ttraining's l1: 14.0779\tvalid_1's rmse: 19.3461\tvalid_1's l1: 14.9948\n",
      "[1700]\ttraining's rmse: 18.2012\ttraining's l1: 14.0531\tvalid_1's rmse: 19.3381\tvalid_1's l1: 14.9894\n",
      "[1750]\ttraining's rmse: 18.1659\ttraining's l1: 14.0272\tvalid_1's rmse: 19.3275\tvalid_1's l1: 14.9819\n",
      "[1800]\ttraining's rmse: 18.1324\ttraining's l1: 14.0035\tvalid_1's rmse: 19.3184\tvalid_1's l1: 14.9757\n",
      "[1850]\ttraining's rmse: 18.1009\ttraining's l1: 13.9804\tvalid_1's rmse: 19.3119\tvalid_1's l1: 14.971\n",
      "[1900]\ttraining's rmse: 18.0689\ttraining's l1: 13.9574\tvalid_1's rmse: 19.3062\tvalid_1's l1: 14.9674\n",
      "[1950]\ttraining's rmse: 18.0372\ttraining's l1: 13.9342\tvalid_1's rmse: 19.2996\tvalid_1's l1: 14.9633\n",
      "[2000]\ttraining's rmse: 18.0057\ttraining's l1: 13.912\tvalid_1's rmse: 19.2915\tvalid_1's l1: 14.958\n",
      "[2050]\ttraining's rmse: 17.9745\ttraining's l1: 13.8896\tvalid_1's rmse: 19.2847\tvalid_1's l1: 14.953\n",
      "[2100]\ttraining's rmse: 17.9448\ttraining's l1: 13.8681\tvalid_1's rmse: 19.2797\tvalid_1's l1: 14.95\n",
      "[2150]\ttraining's rmse: 17.9151\ttraining's l1: 13.8465\tvalid_1's rmse: 19.2748\tvalid_1's l1: 14.947\n",
      "[2200]\ttraining's rmse: 17.8865\ttraining's l1: 13.8259\tvalid_1's rmse: 19.2696\tvalid_1's l1: 14.9438\n",
      "[2250]\ttraining's rmse: 17.8572\ttraining's l1: 13.8046\tvalid_1's rmse: 19.263\tvalid_1's l1: 14.9395\n",
      "[2300]\ttraining's rmse: 17.8296\ttraining's l1: 13.7842\tvalid_1's rmse: 19.2592\tvalid_1's l1: 14.9375\n",
      "[2350]\ttraining's rmse: 17.802\ttraining's l1: 13.7635\tvalid_1's rmse: 19.2555\tvalid_1's l1: 14.9348\n",
      "[2400]\ttraining's rmse: 17.7754\ttraining's l1: 13.7438\tvalid_1's rmse: 19.2517\tvalid_1's l1: 14.9317\n",
      "[2450]\ttraining's rmse: 17.7492\ttraining's l1: 13.7244\tvalid_1's rmse: 19.2496\tvalid_1's l1: 14.9301\n",
      "[2500]\ttraining's rmse: 17.7235\ttraining's l1: 13.7052\tvalid_1's rmse: 19.2469\tvalid_1's l1: 14.9284\n",
      "[2550]\ttraining's rmse: 17.6969\ttraining's l1: 13.6859\tvalid_1's rmse: 19.2435\tvalid_1's l1: 14.926\n",
      "[2600]\ttraining's rmse: 17.6698\ttraining's l1: 13.6662\tvalid_1's rmse: 19.2401\tvalid_1's l1: 14.9238\n",
      "[2650]\ttraining's rmse: 17.6445\ttraining's l1: 13.6476\tvalid_1's rmse: 19.2374\tvalid_1's l1: 14.9225\n",
      "[2700]\ttraining's rmse: 17.6195\ttraining's l1: 13.6294\tvalid_1's rmse: 19.234\tvalid_1's l1: 14.92\n",
      "[2750]\ttraining's rmse: 17.5945\ttraining's l1: 13.611\tvalid_1's rmse: 19.2319\tvalid_1's l1: 14.919\n",
      "[2800]\ttraining's rmse: 17.5699\ttraining's l1: 13.5928\tvalid_1's rmse: 19.229\tvalid_1's l1: 14.9177\n",
      "[2850]\ttraining's rmse: 17.5433\ttraining's l1: 13.5736\tvalid_1's rmse: 19.2256\tvalid_1's l1: 14.915\n",
      "[2900]\ttraining's rmse: 17.5176\ttraining's l1: 13.5554\tvalid_1's rmse: 19.2234\tvalid_1's l1: 14.9133\n",
      "[2950]\ttraining's rmse: 17.4928\ttraining's l1: 13.5378\tvalid_1's rmse: 19.2212\tvalid_1's l1: 14.9119\n",
      "[3000]\ttraining's rmse: 17.4687\ttraining's l1: 13.5199\tvalid_1's rmse: 19.2199\tvalid_1's l1: 14.9106\n",
      "[3050]\ttraining's rmse: 17.4448\ttraining's l1: 13.5022\tvalid_1's rmse: 19.2186\tvalid_1's l1: 14.91\n",
      "[3100]\ttraining's rmse: 17.4212\ttraining's l1: 13.4846\tvalid_1's rmse: 19.2161\tvalid_1's l1: 14.908\n",
      "[3150]\ttraining's rmse: 17.3978\ttraining's l1: 13.4672\tvalid_1's rmse: 19.214\tvalid_1's l1: 14.9066\n",
      "[3200]\ttraining's rmse: 17.3749\ttraining's l1: 13.4503\tvalid_1's rmse: 19.2124\tvalid_1's l1: 14.9054\n",
      "[3250]\ttraining's rmse: 17.3515\ttraining's l1: 13.4329\tvalid_1's rmse: 19.2103\tvalid_1's l1: 14.9037\n",
      "[3300]\ttraining's rmse: 17.3285\ttraining's l1: 13.4162\tvalid_1's rmse: 19.2082\tvalid_1's l1: 14.9025\n",
      "[3350]\ttraining's rmse: 17.3051\ttraining's l1: 13.3992\tvalid_1's rmse: 19.2059\tvalid_1's l1: 14.9006\n",
      "[3400]\ttraining's rmse: 17.2822\ttraining's l1: 13.3818\tvalid_1's rmse: 19.2054\tvalid_1's l1: 14.9001\n",
      "[3450]\ttraining's rmse: 17.2599\ttraining's l1: 13.3651\tvalid_1's rmse: 19.2041\tvalid_1's l1: 14.8992\n",
      "[3500]\ttraining's rmse: 17.2376\ttraining's l1: 13.3486\tvalid_1's rmse: 19.2032\tvalid_1's l1: 14.8987\n",
      "[3550]\ttraining's rmse: 17.2154\ttraining's l1: 13.3316\tvalid_1's rmse: 19.2022\tvalid_1's l1: 14.898\n",
      "[3600]\ttraining's rmse: 17.1929\ttraining's l1: 13.3151\tvalid_1's rmse: 19.2011\tvalid_1's l1: 14.8975\n",
      "[3650]\ttraining's rmse: 17.1703\ttraining's l1: 13.2985\tvalid_1's rmse: 19.2\tvalid_1's l1: 14.8966\n",
      "[3700]\ttraining's rmse: 17.1473\ttraining's l1: 13.2816\tvalid_1's rmse: 19.1993\tvalid_1's l1: 14.8961\n",
      "[3750]\ttraining's rmse: 17.1257\ttraining's l1: 13.2655\tvalid_1's rmse: 19.1995\tvalid_1's l1: 14.8965\n",
      "[3800]\ttraining's rmse: 17.1038\ttraining's l1: 13.249\tvalid_1's rmse: 19.1987\tvalid_1's l1: 14.8962\n",
      "[3850]\ttraining's rmse: 17.0816\ttraining's l1: 13.232\tvalid_1's rmse: 19.1979\tvalid_1's l1: 14.8956\n",
      "[3900]\ttraining's rmse: 17.0599\ttraining's l1: 13.2159\tvalid_1's rmse: 19.1961\tvalid_1's l1: 14.8947\n",
      "[3950]\ttraining's rmse: 17.0384\ttraining's l1: 13.2002\tvalid_1's rmse: 19.1953\tvalid_1's l1: 14.8939\n",
      "[4000]\ttraining's rmse: 17.0171\ttraining's l1: 13.1839\tvalid_1's rmse: 19.1945\tvalid_1's l1: 14.8934\n",
      "[4050]\ttraining's rmse: 16.9958\ttraining's l1: 13.1678\tvalid_1's rmse: 19.1938\tvalid_1's l1: 14.8934\n",
      "[4100]\ttraining's rmse: 16.9727\ttraining's l1: 13.1511\tvalid_1's rmse: 19.1924\tvalid_1's l1: 14.8928\n",
      "[4150]\ttraining's rmse: 16.9514\ttraining's l1: 13.135\tvalid_1's rmse: 19.1915\tvalid_1's l1: 14.8921\n",
      "[4200]\ttraining's rmse: 16.931\ttraining's l1: 13.1199\tvalid_1's rmse: 19.1907\tvalid_1's l1: 14.892\n",
      "[4250]\ttraining's rmse: 16.9093\ttraining's l1: 13.104\tvalid_1's rmse: 19.19\tvalid_1's l1: 14.8915\n",
      "[4300]\ttraining's rmse: 16.8889\ttraining's l1: 13.0887\tvalid_1's rmse: 19.19\tvalid_1's l1: 14.8918\n",
      "[4350]\ttraining's rmse: 16.8672\ttraining's l1: 13.0726\tvalid_1's rmse: 19.1895\tvalid_1's l1: 14.8914\n",
      "[4400]\ttraining's rmse: 16.8474\ttraining's l1: 13.0575\tvalid_1's rmse: 19.1886\tvalid_1's l1: 14.891\n",
      "[4450]\ttraining's rmse: 16.8271\ttraining's l1: 13.0422\tvalid_1's rmse: 19.1889\tvalid_1's l1: 14.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's rmse: 16.8061\ttraining's l1: 13.0261\tvalid_1's rmse: 19.1894\tvalid_1's l1: 14.8918\n",
      "[4550]\ttraining's rmse: 16.7865\ttraining's l1: 13.0109\tvalid_1's rmse: 19.1887\tvalid_1's l1: 14.8913\n",
      "[4600]\ttraining's rmse: 16.7658\ttraining's l1: 12.9954\tvalid_1's rmse: 19.1879\tvalid_1's l1: 14.891\n",
      "[4650]\ttraining's rmse: 16.746\ttraining's l1: 12.9803\tvalid_1's rmse: 19.188\tvalid_1's l1: 14.8911\n",
      "[4700]\ttraining's rmse: 16.7255\ttraining's l1: 12.9649\tvalid_1's rmse: 19.1877\tvalid_1's l1: 14.8907\n",
      "[4750]\ttraining's rmse: 16.7055\ttraining's l1: 12.9499\tvalid_1's rmse: 19.1877\tvalid_1's l1: 14.8908\n",
      "[4800]\ttraining's rmse: 16.6857\ttraining's l1: 12.9349\tvalid_1's rmse: 19.1885\tvalid_1's l1: 14.8913\n",
      "[4850]\ttraining's rmse: 16.6662\ttraining's l1: 12.9198\tvalid_1's rmse: 19.1878\tvalid_1's l1: 14.8909\n",
      "Early stopping, best iteration is:\n",
      "[4620]\ttraining's rmse: 16.7579\ttraining's l1: 12.9895\tvalid_1's rmse: 19.1876\tvalid_1's l1: 14.8905\n",
      "****************************************************************************************************\n",
      "MAE Model 0.0628546330443074\n",
      "MSE Model 0.06293077681140374\n",
      "Merge Model12 0.0630345388308981\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's l1: 27.6725\tvalid_1's l1: 27.9664\n",
      "[100]\ttraining's l1: 23.9317\tvalid_1's l1: 24.2505\n",
      "[150]\ttraining's l1: 21.2667\tvalid_1's l1: 21.5643\n",
      "[200]\ttraining's l1: 19.3894\tvalid_1's l1: 19.6493\n",
      "[250]\ttraining's l1: 18.0801\tvalid_1's l1: 18.2993\n",
      "[300]\ttraining's l1: 17.1651\tvalid_1's l1: 17.3587\n",
      "[350]\ttraining's l1: 16.5243\tvalid_1's l1: 16.7118\n",
      "[400]\ttraining's l1: 16.0651\tvalid_1's l1: 16.2634\n",
      "[450]\ttraining's l1: 15.7272\tvalid_1's l1: 15.9428\n",
      "[500]\ttraining's l1: 15.4766\tvalid_1's l1: 15.7123\n",
      "[550]\ttraining's l1: 15.2844\tvalid_1's l1: 15.5446\n",
      "[600]\ttraining's l1: 15.1307\tvalid_1's l1: 15.4183\n",
      "[650]\ttraining's l1: 15.0076\tvalid_1's l1: 15.3202\n",
      "[700]\ttraining's l1: 14.902\tvalid_1's l1: 15.2439\n",
      "[750]\ttraining's l1: 14.8136\tvalid_1's l1: 15.1827\n",
      "[800]\ttraining's l1: 14.7324\tvalid_1's l1: 15.1303\n",
      "[850]\ttraining's l1: 14.6612\tvalid_1's l1: 15.087\n",
      "[900]\ttraining's l1: 14.5992\tvalid_1's l1: 15.0504\n",
      "[950]\ttraining's l1: 14.5441\tvalid_1's l1: 15.0218\n",
      "[1000]\ttraining's l1: 14.4927\tvalid_1's l1: 14.9966\n",
      "[1050]\ttraining's l1: 14.4449\tvalid_1's l1: 14.9738\n",
      "[1100]\ttraining's l1: 14.3993\tvalid_1's l1: 14.9505\n",
      "[1150]\ttraining's l1: 14.358\tvalid_1's l1: 14.9343\n",
      "[1200]\ttraining's l1: 14.3195\tvalid_1's l1: 14.9181\n",
      "[1250]\ttraining's l1: 14.2829\tvalid_1's l1: 14.9046\n",
      "[1300]\ttraining's l1: 14.2484\tvalid_1's l1: 14.8934\n",
      "[1350]\ttraining's l1: 14.2162\tvalid_1's l1: 14.8838\n",
      "[1400]\ttraining's l1: 14.1855\tvalid_1's l1: 14.8749\n",
      "[1450]\ttraining's l1: 14.1564\tvalid_1's l1: 14.8679\n",
      "[1500]\ttraining's l1: 14.1284\tvalid_1's l1: 14.8605\n",
      "[1550]\ttraining's l1: 14.1004\tvalid_1's l1: 14.8547\n",
      "[1600]\ttraining's l1: 14.0734\tvalid_1's l1: 14.8479\n",
      "[1650]\ttraining's l1: 14.0469\tvalid_1's l1: 14.8419\n",
      "[1700]\ttraining's l1: 14.0224\tvalid_1's l1: 14.8377\n",
      "[1750]\ttraining's l1: 13.9971\tvalid_1's l1: 14.8328\n",
      "[1800]\ttraining's l1: 13.9729\tvalid_1's l1: 14.8279\n",
      "[1850]\ttraining's l1: 13.9491\tvalid_1's l1: 14.8229\n",
      "[1900]\ttraining's l1: 13.927\tvalid_1's l1: 14.8195\n",
      "[1950]\ttraining's l1: 13.9043\tvalid_1's l1: 14.8152\n",
      "[2000]\ttraining's l1: 13.8823\tvalid_1's l1: 14.8119\n",
      "[2050]\ttraining's l1: 13.862\tvalid_1's l1: 14.809\n",
      "[2100]\ttraining's l1: 13.8412\tvalid_1's l1: 14.8068\n",
      "[2150]\ttraining's l1: 13.8217\tvalid_1's l1: 14.8047\n",
      "[2200]\ttraining's l1: 13.802\tvalid_1's l1: 14.8026\n",
      "[2250]\ttraining's l1: 13.7824\tvalid_1's l1: 14.8007\n",
      "[2300]\ttraining's l1: 13.7625\tvalid_1's l1: 14.7985\n",
      "[2350]\ttraining's l1: 13.7428\tvalid_1's l1: 14.7965\n",
      "[2400]\ttraining's l1: 13.724\tvalid_1's l1: 14.7953\n",
      "[2450]\ttraining's l1: 13.705\tvalid_1's l1: 14.7931\n",
      "[2500]\ttraining's l1: 13.685\tvalid_1's l1: 14.7912\n",
      "[2550]\ttraining's l1: 13.6662\tvalid_1's l1: 14.7882\n",
      "[2600]\ttraining's l1: 13.6474\tvalid_1's l1: 14.7867\n",
      "[2650]\ttraining's l1: 13.6286\tvalid_1's l1: 14.7846\n",
      "[2700]\ttraining's l1: 13.6112\tvalid_1's l1: 14.7836\n",
      "[2750]\ttraining's l1: 13.5934\tvalid_1's l1: 14.7822\n",
      "[2800]\ttraining's l1: 13.5757\tvalid_1's l1: 14.7805\n",
      "[2850]\ttraining's l1: 13.5574\tvalid_1's l1: 14.7793\n",
      "[2900]\ttraining's l1: 13.5393\tvalid_1's l1: 14.7773\n",
      "[2950]\ttraining's l1: 13.522\tvalid_1's l1: 14.7759\n",
      "[3000]\ttraining's l1: 13.5051\tvalid_1's l1: 14.7747\n",
      "[3050]\ttraining's l1: 13.4881\tvalid_1's l1: 14.7732\n",
      "[3100]\ttraining's l1: 13.4725\tvalid_1's l1: 14.7725\n",
      "[3150]\ttraining's l1: 13.4558\tvalid_1's l1: 14.771\n",
      "[3200]\ttraining's l1: 13.4396\tvalid_1's l1: 14.7705\n",
      "[3250]\ttraining's l1: 13.4239\tvalid_1's l1: 14.7693\n",
      "[3300]\ttraining's l1: 13.4084\tvalid_1's l1: 14.7681\n",
      "[3350]\ttraining's l1: 13.3931\tvalid_1's l1: 14.7686\n",
      "[3400]\ttraining's l1: 13.3766\tvalid_1's l1: 14.767\n",
      "[3450]\ttraining's l1: 13.361\tvalid_1's l1: 14.7664\n",
      "[3500]\ttraining's l1: 13.3453\tvalid_1's l1: 14.7654\n",
      "[3550]\ttraining's l1: 13.3296\tvalid_1's l1: 14.7639\n",
      "[3600]\ttraining's l1: 13.3138\tvalid_1's l1: 14.763\n",
      "[3650]\ttraining's l1: 13.2983\tvalid_1's l1: 14.7618\n",
      "[3700]\ttraining's l1: 13.2833\tvalid_1's l1: 14.7613\n",
      "[3750]\ttraining's l1: 13.2685\tvalid_1's l1: 14.7604\n",
      "[3800]\ttraining's l1: 13.2548\tvalid_1's l1: 14.7601\n",
      "[3850]\ttraining's l1: 13.24\tvalid_1's l1: 14.7602\n",
      "[3900]\ttraining's l1: 13.2254\tvalid_1's l1: 14.7596\n",
      "[3950]\ttraining's l1: 13.2107\tvalid_1's l1: 14.7595\n",
      "[4000]\ttraining's l1: 13.1954\tvalid_1's l1: 14.7583\n",
      "[4050]\ttraining's l1: 13.1817\tvalid_1's l1: 14.7584\n",
      "[4100]\ttraining's l1: 13.1676\tvalid_1's l1: 14.7574\n",
      "[4150]\ttraining's l1: 13.154\tvalid_1's l1: 14.7562\n",
      "[4200]\ttraining's l1: 13.1401\tvalid_1's l1: 14.7551\n",
      "[4250]\ttraining's l1: 13.1259\tvalid_1's l1: 14.7536\n",
      "[4300]\ttraining's l1: 13.1118\tvalid_1's l1: 14.7523\n",
      "[4350]\ttraining's l1: 13.0988\tvalid_1's l1: 14.7516\n",
      "[4400]\ttraining's l1: 13.085\tvalid_1's l1: 14.7507\n",
      "[4450]\ttraining's l1: 13.0721\tvalid_1's l1: 14.7501\n",
      "[4500]\ttraining's l1: 13.0589\tvalid_1's l1: 14.7497\n",
      "[4550]\ttraining's l1: 13.0448\tvalid_1's l1: 14.7489\n",
      "[4600]\ttraining's l1: 13.0314\tvalid_1's l1: 14.7486\n",
      "[4650]\ttraining's l1: 13.0195\tvalid_1's l1: 14.7481\n",
      "[4700]\ttraining's l1: 13.0073\tvalid_1's l1: 14.7478\n",
      "[4750]\ttraining's l1: 12.9948\tvalid_1's l1: 14.7471\n",
      "[4800]\ttraining's l1: 12.9824\tvalid_1's l1: 14.7469\n",
      "[4850]\ttraining's l1: 12.9689\tvalid_1's l1: 14.7458\n",
      "[4900]\ttraining's l1: 12.9562\tvalid_1's l1: 14.7458\n",
      "[4950]\ttraining's l1: 12.9448\tvalid_1's l1: 14.7459\n",
      "[5000]\ttraining's l1: 12.9332\tvalid_1's l1: 14.7461\n",
      "[5050]\ttraining's l1: 12.9212\tvalid_1's l1: 14.7456\n",
      "[5100]\ttraining's l1: 12.9104\tvalid_1's l1: 14.746\n",
      "[5150]\ttraining's l1: 12.9012\tvalid_1's l1: 14.7463\n",
      "[5200]\ttraining's l1: 12.8892\tvalid_1's l1: 14.7458\n",
      "[5250]\ttraining's l1: 12.8791\tvalid_1's l1: 14.7463\n",
      "[5300]\ttraining's l1: 12.8697\tvalid_1's l1: 14.7462\n",
      "Early stopping, best iteration is:\n",
      "[5054]\ttraining's l1: 12.9203\tvalid_1's l1: 14.7455\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's rmse: 35.7645\ttraining's l1: 28.1186\tvalid_1's rmse: 35.8855\tvalid_1's l1: 28.2852\n",
      "[100]\ttraining's rmse: 30.9178\ttraining's l1: 24.1332\tvalid_1's rmse: 31.0091\tvalid_1's l1: 24.2888\n",
      "[150]\ttraining's rmse: 27.4688\ttraining's l1: 21.305\tvalid_1's rmse: 27.5627\tvalid_1's l1: 21.44\n",
      "[200]\ttraining's rmse: 25.0426\ttraining's l1: 19.3272\tvalid_1's rmse: 25.1672\tvalid_1's l1: 19.4741\n",
      "[250]\ttraining's rmse: 23.3561\ttraining's l1: 17.971\tvalid_1's rmse: 23.5203\tvalid_1's l1: 18.1304\n",
      "[300]\ttraining's rmse: 22.1879\ttraining's l1: 17.0498\tvalid_1's rmse: 22.3992\tvalid_1's l1: 17.222\n",
      "[350]\ttraining's rmse: 21.3765\ttraining's l1: 16.4233\tvalid_1's rmse: 21.6359\tvalid_1's l1: 16.6039\n",
      "[400]\ttraining's rmse: 20.8045\ttraining's l1: 15.9846\tvalid_1's rmse: 21.1083\tvalid_1's l1: 16.1767\n",
      "[450]\ttraining's rmse: 20.3908\ttraining's l1: 15.6702\tvalid_1's rmse: 20.7408\tvalid_1's l1: 15.8816\n",
      "[500]\ttraining's rmse: 20.0813\ttraining's l1: 15.4386\tvalid_1's rmse: 20.4739\tvalid_1's l1: 15.6673\n",
      "[550]\ttraining's rmse: 19.845\ttraining's l1: 15.2656\tvalid_1's rmse: 20.2806\tvalid_1's l1: 15.5103\n",
      "[600]\ttraining's rmse: 19.657\ttraining's l1: 15.1284\tvalid_1's rmse: 20.1323\tvalid_1's l1: 15.3932\n",
      "[650]\ttraining's rmse: 19.5033\ttraining's l1: 15.0172\tvalid_1's rmse: 20.018\tvalid_1's l1: 15.3031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 19.3715\ttraining's l1: 14.9224\tvalid_1's rmse: 19.924\tvalid_1's l1: 15.2318\n",
      "[750]\ttraining's rmse: 19.2556\ttraining's l1: 14.837\tvalid_1's rmse: 19.8481\tvalid_1's l1: 15.1715\n",
      "[800]\ttraining's rmse: 19.1554\ttraining's l1: 14.7633\tvalid_1's rmse: 19.7854\tvalid_1's l1: 15.1233\n",
      "[850]\ttraining's rmse: 19.0642\ttraining's l1: 14.6966\tvalid_1's rmse: 19.7309\tvalid_1's l1: 15.0805\n",
      "[900]\ttraining's rmse: 18.9841\ttraining's l1: 14.638\tvalid_1's rmse: 19.6888\tvalid_1's l1: 15.0463\n",
      "[950]\ttraining's rmse: 18.9094\ttraining's l1: 14.584\tvalid_1's rmse: 19.647\tvalid_1's l1: 15.0136\n",
      "[1000]\ttraining's rmse: 18.8407\ttraining's l1: 14.534\tvalid_1's rmse: 19.6113\tvalid_1's l1: 14.986\n",
      "[1050]\ttraining's rmse: 18.7775\ttraining's l1: 14.4887\tvalid_1's rmse: 19.581\tvalid_1's l1: 14.9631\n",
      "[1100]\ttraining's rmse: 18.7172\ttraining's l1: 14.4459\tvalid_1's rmse: 19.5534\tvalid_1's l1: 14.9434\n",
      "[1150]\ttraining's rmse: 18.6604\ttraining's l1: 14.405\tvalid_1's rmse: 19.5276\tvalid_1's l1: 14.9256\n",
      "[1200]\ttraining's rmse: 18.6066\ttraining's l1: 14.3667\tvalid_1's rmse: 19.504\tvalid_1's l1: 14.9078\n",
      "[1250]\ttraining's rmse: 18.5552\ttraining's l1: 14.3294\tvalid_1's rmse: 19.4826\tvalid_1's l1: 14.8925\n",
      "[1300]\ttraining's rmse: 18.5075\ttraining's l1: 14.295\tvalid_1's rmse: 19.4637\tvalid_1's l1: 14.8788\n",
      "[1350]\ttraining's rmse: 18.4624\ttraining's l1: 14.2624\tvalid_1's rmse: 19.4472\tvalid_1's l1: 14.8669\n",
      "[1400]\ttraining's rmse: 18.4192\ttraining's l1: 14.2312\tvalid_1's rmse: 19.4313\tvalid_1's l1: 14.8555\n",
      "[1450]\ttraining's rmse: 18.3783\ttraining's l1: 14.202\tvalid_1's rmse: 19.4192\tvalid_1's l1: 14.8471\n",
      "[1500]\ttraining's rmse: 18.3376\ttraining's l1: 14.1728\tvalid_1's rmse: 19.4073\tvalid_1's l1: 14.8393\n",
      "[1550]\ttraining's rmse: 18.2989\ttraining's l1: 14.145\tvalid_1's rmse: 19.3954\tvalid_1's l1: 14.8318\n",
      "[1600]\ttraining's rmse: 18.2635\ttraining's l1: 14.1191\tvalid_1's rmse: 19.3863\tvalid_1's l1: 14.8256\n",
      "[1650]\ttraining's rmse: 18.2269\ttraining's l1: 14.0925\tvalid_1's rmse: 19.3772\tvalid_1's l1: 14.8197\n",
      "[1700]\ttraining's rmse: 18.1919\ttraining's l1: 14.0671\tvalid_1's rmse: 19.3689\tvalid_1's l1: 14.8142\n",
      "[1750]\ttraining's rmse: 18.1564\ttraining's l1: 14.0418\tvalid_1's rmse: 19.3614\tvalid_1's l1: 14.8099\n",
      "[1800]\ttraining's rmse: 18.1244\ttraining's l1: 14.019\tvalid_1's rmse: 19.3564\tvalid_1's l1: 14.8076\n",
      "[1850]\ttraining's rmse: 18.092\ttraining's l1: 13.9957\tvalid_1's rmse: 19.3506\tvalid_1's l1: 14.8038\n",
      "[1900]\ttraining's rmse: 18.0594\ttraining's l1: 13.9723\tvalid_1's rmse: 19.3445\tvalid_1's l1: 14.8005\n",
      "[1950]\ttraining's rmse: 18.0281\ttraining's l1: 13.9502\tvalid_1's rmse: 19.3385\tvalid_1's l1: 14.7974\n",
      "[2000]\ttraining's rmse: 17.9981\ttraining's l1: 13.9282\tvalid_1's rmse: 19.3337\tvalid_1's l1: 14.7945\n",
      "[2050]\ttraining's rmse: 17.9675\ttraining's l1: 13.906\tvalid_1's rmse: 19.3295\tvalid_1's l1: 14.7928\n",
      "[2100]\ttraining's rmse: 17.9374\ttraining's l1: 13.8841\tvalid_1's rmse: 19.3252\tvalid_1's l1: 14.7897\n",
      "[2150]\ttraining's rmse: 17.908\ttraining's l1: 13.8631\tvalid_1's rmse: 19.3206\tvalid_1's l1: 14.787\n",
      "[2200]\ttraining's rmse: 17.8803\ttraining's l1: 13.8431\tvalid_1's rmse: 19.3186\tvalid_1's l1: 14.7864\n",
      "[2250]\ttraining's rmse: 17.8513\ttraining's l1: 13.8221\tvalid_1's rmse: 19.3157\tvalid_1's l1: 14.7854\n",
      "[2300]\ttraining's rmse: 17.8225\ttraining's l1: 13.8017\tvalid_1's rmse: 19.3121\tvalid_1's l1: 14.7837\n",
      "[2350]\ttraining's rmse: 17.7946\ttraining's l1: 13.7811\tvalid_1's rmse: 19.3093\tvalid_1's l1: 14.7825\n",
      "[2400]\ttraining's rmse: 17.7678\ttraining's l1: 13.7611\tvalid_1's rmse: 19.3066\tvalid_1's l1: 14.781\n",
      "[2450]\ttraining's rmse: 17.7416\ttraining's l1: 13.7419\tvalid_1's rmse: 19.3046\tvalid_1's l1: 14.7804\n",
      "[2500]\ttraining's rmse: 17.7145\ttraining's l1: 13.7224\tvalid_1's rmse: 19.3022\tvalid_1's l1: 14.78\n",
      "[2550]\ttraining's rmse: 17.6894\ttraining's l1: 13.7039\tvalid_1's rmse: 19.3012\tvalid_1's l1: 14.7802\n",
      "[2600]\ttraining's rmse: 17.6636\ttraining's l1: 13.6846\tvalid_1's rmse: 19.2981\tvalid_1's l1: 14.7786\n",
      "[2650]\ttraining's rmse: 17.6372\ttraining's l1: 13.6658\tvalid_1's rmse: 19.2949\tvalid_1's l1: 14.7774\n",
      "[2700]\ttraining's rmse: 17.611\ttraining's l1: 13.6466\tvalid_1's rmse: 19.2929\tvalid_1's l1: 14.7771\n",
      "[2750]\ttraining's rmse: 17.5866\ttraining's l1: 13.6283\tvalid_1's rmse: 19.2905\tvalid_1's l1: 14.7763\n",
      "[2800]\ttraining's rmse: 17.5616\ttraining's l1: 13.6103\tvalid_1's rmse: 19.2884\tvalid_1's l1: 14.7756\n",
      "[2850]\ttraining's rmse: 17.5356\ttraining's l1: 13.5912\tvalid_1's rmse: 19.2868\tvalid_1's l1: 14.7745\n",
      "[2900]\ttraining's rmse: 17.5106\ttraining's l1: 13.5728\tvalid_1's rmse: 19.2847\tvalid_1's l1: 14.7739\n",
      "[2950]\ttraining's rmse: 17.4862\ttraining's l1: 13.5548\tvalid_1's rmse: 19.2828\tvalid_1's l1: 14.7732\n",
      "[3000]\ttraining's rmse: 17.4624\ttraining's l1: 13.5371\tvalid_1's rmse: 19.2812\tvalid_1's l1: 14.7726\n",
      "[3050]\ttraining's rmse: 17.4387\ttraining's l1: 13.5195\tvalid_1's rmse: 19.28\tvalid_1's l1: 14.772\n",
      "[3100]\ttraining's rmse: 17.4143\ttraining's l1: 13.5011\tvalid_1's rmse: 19.2794\tvalid_1's l1: 14.7716\n",
      "[3150]\ttraining's rmse: 17.39\ttraining's l1: 13.4829\tvalid_1's rmse: 19.2778\tvalid_1's l1: 14.7713\n",
      "[3200]\ttraining's rmse: 17.3671\ttraining's l1: 13.4657\tvalid_1's rmse: 19.2771\tvalid_1's l1: 14.7719\n",
      "[3250]\ttraining's rmse: 17.3429\ttraining's l1: 13.4482\tvalid_1's rmse: 19.2752\tvalid_1's l1: 14.7712\n",
      "[3300]\ttraining's rmse: 17.321\ttraining's l1: 13.4314\tvalid_1's rmse: 19.2752\tvalid_1's l1: 14.7712\n",
      "[3350]\ttraining's rmse: 17.2973\ttraining's l1: 13.4138\tvalid_1's rmse: 19.2745\tvalid_1's l1: 14.7716\n",
      "[3400]\ttraining's rmse: 17.2747\ttraining's l1: 13.397\tvalid_1's rmse: 19.2739\tvalid_1's l1: 14.7718\n",
      "[3450]\ttraining's rmse: 17.2517\ttraining's l1: 13.3803\tvalid_1's rmse: 19.2726\tvalid_1's l1: 14.7714\n",
      "Early stopping, best iteration is:\n",
      "[3224]\ttraining's rmse: 17.3549\ttraining's l1: 13.4571\tvalid_1's rmse: 19.2752\tvalid_1's l1: 14.7707\n",
      "****************************************************************************************************\n",
      "MAE Model 0.06351003577031475\n",
      "MSE Model 0.06340887540272247\n",
      "Merge Model12 0.06353987757927138\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's l1: 27.7034\tvalid_1's l1: 27.7111\n",
      "[100]\ttraining's l1: 23.9635\tvalid_1's l1: 23.9892\n",
      "[150]\ttraining's l1: 21.2965\tvalid_1's l1: 21.3436\n",
      "[200]\ttraining's l1: 19.4121\tvalid_1's l1: 19.4912\n",
      "[250]\ttraining's l1: 18.0948\tvalid_1's l1: 18.2084\n",
      "[300]\ttraining's l1: 17.1788\tvalid_1's l1: 17.3315\n",
      "[350]\ttraining's l1: 16.5376\tvalid_1's l1: 16.7187\n",
      "[400]\ttraining's l1: 16.0786\tvalid_1's l1: 16.2863\n",
      "[450]\ttraining's l1: 15.7448\tvalid_1's l1: 15.9735\n",
      "[500]\ttraining's l1: 15.5\tvalid_1's l1: 15.7425\n",
      "[550]\ttraining's l1: 15.3107\tvalid_1's l1: 15.5663\n",
      "[600]\ttraining's l1: 15.1586\tvalid_1's l1: 15.4271\n",
      "[650]\ttraining's l1: 15.037\tvalid_1's l1: 15.3167\n",
      "[700]\ttraining's l1: 14.9339\tvalid_1's l1: 15.2283\n",
      "[750]\ttraining's l1: 14.8442\tvalid_1's l1: 15.1543\n",
      "[800]\ttraining's l1: 14.7654\tvalid_1's l1: 15.0928\n",
      "[850]\ttraining's l1: 14.6944\tvalid_1's l1: 15.0382\n",
      "[900]\ttraining's l1: 14.6338\tvalid_1's l1: 14.9951\n",
      "[950]\ttraining's l1: 14.5801\tvalid_1's l1: 14.9588\n",
      "[1000]\ttraining's l1: 14.5313\tvalid_1's l1: 14.9272\n",
      "[1050]\ttraining's l1: 14.4846\tvalid_1's l1: 14.899\n",
      "[1100]\ttraining's l1: 14.4422\tvalid_1's l1: 14.8766\n",
      "[1150]\ttraining's l1: 14.4004\tvalid_1's l1: 14.8541\n",
      "[1200]\ttraining's l1: 14.3605\tvalid_1's l1: 14.8328\n",
      "[1250]\ttraining's l1: 14.3256\tvalid_1's l1: 14.8158\n",
      "[1300]\ttraining's l1: 14.2907\tvalid_1's l1: 14.799\n",
      "[1350]\ttraining's l1: 14.2587\tvalid_1's l1: 14.7858\n",
      "[1400]\ttraining's l1: 14.2276\tvalid_1's l1: 14.7735\n",
      "[1450]\ttraining's l1: 14.1992\tvalid_1's l1: 14.7632\n",
      "[1500]\ttraining's l1: 14.1707\tvalid_1's l1: 14.7542\n",
      "[1550]\ttraining's l1: 14.1414\tvalid_1's l1: 14.7439\n",
      "[1600]\ttraining's l1: 14.1167\tvalid_1's l1: 14.7382\n",
      "[1650]\ttraining's l1: 14.0915\tvalid_1's l1: 14.7308\n",
      "[1700]\ttraining's l1: 14.0669\tvalid_1's l1: 14.7242\n",
      "[1750]\ttraining's l1: 14.0421\tvalid_1's l1: 14.7172\n",
      "[1800]\ttraining's l1: 14.0185\tvalid_1's l1: 14.711\n",
      "[1850]\ttraining's l1: 13.9948\tvalid_1's l1: 14.705\n",
      "[1900]\ttraining's l1: 13.972\tvalid_1's l1: 14.6996\n",
      "[1950]\ttraining's l1: 13.9502\tvalid_1's l1: 14.6956\n",
      "[2000]\ttraining's l1: 13.9288\tvalid_1's l1: 14.6919\n",
      "[2050]\ttraining's l1: 13.9081\tvalid_1's l1: 14.6884\n",
      "[2100]\ttraining's l1: 13.8872\tvalid_1's l1: 14.6848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2150]\ttraining's l1: 13.8667\tvalid_1's l1: 14.6821\n",
      "[2200]\ttraining's l1: 13.8462\tvalid_1's l1: 14.6784\n",
      "[2250]\ttraining's l1: 13.8257\tvalid_1's l1: 14.6748\n",
      "[2300]\ttraining's l1: 13.8069\tvalid_1's l1: 14.6727\n",
      "[2350]\ttraining's l1: 13.787\tvalid_1's l1: 14.6687\n",
      "[2400]\ttraining's l1: 13.7672\tvalid_1's l1: 14.6649\n",
      "[2450]\ttraining's l1: 13.7486\tvalid_1's l1: 14.6626\n",
      "[2500]\ttraining's l1: 13.73\tvalid_1's l1: 14.6592\n",
      "[2550]\ttraining's l1: 13.7121\tvalid_1's l1: 14.6573\n",
      "[2600]\ttraining's l1: 13.6932\tvalid_1's l1: 14.6549\n",
      "[2650]\ttraining's l1: 13.6746\tvalid_1's l1: 14.6508\n",
      "[2700]\ttraining's l1: 13.6579\tvalid_1's l1: 14.6486\n",
      "[2750]\ttraining's l1: 13.6402\tvalid_1's l1: 14.6463\n",
      "[2800]\ttraining's l1: 13.6233\tvalid_1's l1: 14.6443\n",
      "[2850]\ttraining's l1: 13.6046\tvalid_1's l1: 14.6415\n",
      "[2900]\ttraining's l1: 13.5873\tvalid_1's l1: 14.6392\n",
      "[2950]\ttraining's l1: 13.5707\tvalid_1's l1: 14.6369\n",
      "[3000]\ttraining's l1: 13.5545\tvalid_1's l1: 14.6353\n",
      "[3050]\ttraining's l1: 13.5378\tvalid_1's l1: 14.6338\n",
      "[3100]\ttraining's l1: 13.5205\tvalid_1's l1: 14.6317\n",
      "[3150]\ttraining's l1: 13.5037\tvalid_1's l1: 14.6292\n",
      "[3200]\ttraining's l1: 13.4881\tvalid_1's l1: 14.6284\n",
      "[3250]\ttraining's l1: 13.471\tvalid_1's l1: 14.6266\n",
      "[3300]\ttraining's l1: 13.4547\tvalid_1's l1: 14.6246\n",
      "[3350]\ttraining's l1: 13.4383\tvalid_1's l1: 14.6228\n",
      "[3400]\ttraining's l1: 13.4222\tvalid_1's l1: 14.6212\n",
      "[3450]\ttraining's l1: 13.4065\tvalid_1's l1: 14.6195\n",
      "[3500]\ttraining's l1: 13.3914\tvalid_1's l1: 14.6183\n",
      "[3550]\ttraining's l1: 13.3766\tvalid_1's l1: 14.6173\n",
      "[3600]\ttraining's l1: 13.3616\tvalid_1's l1: 14.6167\n",
      "[3650]\ttraining's l1: 13.3467\tvalid_1's l1: 14.615\n",
      "[3700]\ttraining's l1: 13.3329\tvalid_1's l1: 14.6141\n",
      "[3750]\ttraining's l1: 13.3181\tvalid_1's l1: 14.6125\n",
      "[3800]\ttraining's l1: 13.3043\tvalid_1's l1: 14.6112\n",
      "[3850]\ttraining's l1: 13.29\tvalid_1's l1: 14.6101\n",
      "[3900]\ttraining's l1: 13.2753\tvalid_1's l1: 14.6082\n",
      "[3950]\ttraining's l1: 13.261\tvalid_1's l1: 14.6077\n",
      "[4000]\ttraining's l1: 13.2466\tvalid_1's l1: 14.6059\n",
      "[4050]\ttraining's l1: 13.2324\tvalid_1's l1: 14.6045\n",
      "[4100]\ttraining's l1: 13.2189\tvalid_1's l1: 14.6034\n",
      "[4150]\ttraining's l1: 13.2065\tvalid_1's l1: 14.6025\n",
      "[4200]\ttraining's l1: 13.1933\tvalid_1's l1: 14.6021\n",
      "[4250]\ttraining's l1: 13.1798\tvalid_1's l1: 14.6005\n",
      "[4300]\ttraining's l1: 13.1668\tvalid_1's l1: 14.5999\n",
      "[4350]\ttraining's l1: 13.1539\tvalid_1's l1: 14.5992\n",
      "[4400]\ttraining's l1: 13.1405\tvalid_1's l1: 14.5985\n",
      "[4450]\ttraining's l1: 13.1271\tvalid_1's l1: 14.5973\n",
      "[4500]\ttraining's l1: 13.1138\tvalid_1's l1: 14.5959\n",
      "[4550]\ttraining's l1: 13.101\tvalid_1's l1: 14.5955\n",
      "[4600]\ttraining's l1: 13.0881\tvalid_1's l1: 14.595\n",
      "[4650]\ttraining's l1: 13.0753\tvalid_1's l1: 14.5942\n",
      "[4700]\ttraining's l1: 13.0632\tvalid_1's l1: 14.5933\n",
      "[4750]\ttraining's l1: 13.0511\tvalid_1's l1: 14.5929\n",
      "[4800]\ttraining's l1: 13.0394\tvalid_1's l1: 14.5921\n",
      "[4850]\ttraining's l1: 13.0269\tvalid_1's l1: 14.5913\n",
      "[4900]\ttraining's l1: 13.0155\tvalid_1's l1: 14.5913\n",
      "[4950]\ttraining's l1: 13.0046\tvalid_1's l1: 14.5911\n",
      "[5000]\ttraining's l1: 12.9928\tvalid_1's l1: 14.5908\n",
      "[5050]\ttraining's l1: 12.9805\tvalid_1's l1: 14.5898\n",
      "[5100]\ttraining's l1: 12.969\tvalid_1's l1: 14.5892\n",
      "[5150]\ttraining's l1: 12.9576\tvalid_1's l1: 14.5888\n",
      "[5200]\ttraining's l1: 12.9467\tvalid_1's l1: 14.5882\n",
      "[5250]\ttraining's l1: 12.9354\tvalid_1's l1: 14.5878\n",
      "[5300]\ttraining's l1: 12.9241\tvalid_1's l1: 14.5875\n",
      "[5350]\ttraining's l1: 12.9123\tvalid_1's l1: 14.5868\n",
      "[5400]\ttraining's l1: 12.901\tvalid_1's l1: 14.5861\n",
      "[5450]\ttraining's l1: 12.8902\tvalid_1's l1: 14.5856\n",
      "[5500]\ttraining's l1: 12.8785\tvalid_1's l1: 14.5847\n",
      "[5550]\ttraining's l1: 12.8682\tvalid_1's l1: 14.5849\n",
      "[5600]\ttraining's l1: 12.8567\tvalid_1's l1: 14.584\n",
      "[5650]\ttraining's l1: 12.847\tvalid_1's l1: 14.5837\n",
      "[5700]\ttraining's l1: 12.8367\tvalid_1's l1: 14.5833\n",
      "[5750]\ttraining's l1: 12.8275\tvalid_1's l1: 14.5833\n",
      "[5800]\ttraining's l1: 12.8193\tvalid_1's l1: 14.5832\n",
      "[5850]\ttraining's l1: 12.8097\tvalid_1's l1: 14.5831\n",
      "[5900]\ttraining's l1: 12.7986\tvalid_1's l1: 14.5829\n",
      "[5950]\ttraining's l1: 12.7886\tvalid_1's l1: 14.582\n",
      "[6000]\ttraining's l1: 12.7794\tvalid_1's l1: 14.5821\n",
      "[6050]\ttraining's l1: 12.7707\tvalid_1's l1: 14.5818\n",
      "[6100]\ttraining's l1: 12.7626\tvalid_1's l1: 14.5817\n",
      "[6150]\ttraining's l1: 12.7553\tvalid_1's l1: 14.5818\n",
      "[6200]\ttraining's l1: 12.7481\tvalid_1's l1: 14.5813\n",
      "[6250]\ttraining's l1: 12.7414\tvalid_1's l1: 14.5815\n",
      "[6300]\ttraining's l1: 12.734\tvalid_1's l1: 14.5817\n",
      "[6350]\ttraining's l1: 12.7263\tvalid_1's l1: 14.5813\n",
      "[6400]\ttraining's l1: 12.7183\tvalid_1's l1: 14.581\n",
      "[6450]\ttraining's l1: 12.7087\tvalid_1's l1: 14.5807\n",
      "[6500]\ttraining's l1: 12.6992\tvalid_1's l1: 14.5803\n",
      "[6550]\ttraining's l1: 12.6904\tvalid_1's l1: 14.5801\n",
      "[6600]\ttraining's l1: 12.6832\tvalid_1's l1: 14.5798\n",
      "[6650]\ttraining's l1: 12.6741\tvalid_1's l1: 14.5796\n",
      "[6700]\ttraining's l1: 12.6665\tvalid_1's l1: 14.5791\n",
      "[6750]\ttraining's l1: 12.6578\tvalid_1's l1: 14.5789\n",
      "[6800]\ttraining's l1: 12.6489\tvalid_1's l1: 14.5785\n",
      "[6850]\ttraining's l1: 12.64\tvalid_1's l1: 14.5785\n",
      "[6900]\ttraining's l1: 12.6311\tvalid_1's l1: 14.5779\n",
      "[6950]\ttraining's l1: 12.6219\tvalid_1's l1: 14.5775\n",
      "[7000]\ttraining's l1: 12.6137\tvalid_1's l1: 14.5774\n",
      "[7050]\ttraining's l1: 12.6047\tvalid_1's l1: 14.5769\n",
      "[7100]\ttraining's l1: 12.5959\tvalid_1's l1: 14.5769\n",
      "[7150]\ttraining's l1: 12.5856\tvalid_1's l1: 14.5765\n",
      "[7200]\ttraining's l1: 12.5758\tvalid_1's l1: 14.576\n",
      "[7250]\ttraining's l1: 12.5662\tvalid_1's l1: 14.5754\n",
      "[7300]\ttraining's l1: 12.5569\tvalid_1's l1: 14.5742\n",
      "[7350]\ttraining's l1: 12.5471\tvalid_1's l1: 14.5736\n",
      "[7400]\ttraining's l1: 12.5383\tvalid_1's l1: 14.5727\n",
      "[7450]\ttraining's l1: 12.5291\tvalid_1's l1: 14.5722\n",
      "[7500]\ttraining's l1: 12.5204\tvalid_1's l1: 14.5721\n",
      "[7550]\ttraining's l1: 12.5111\tvalid_1's l1: 14.5716\n",
      "[7600]\ttraining's l1: 12.5028\tvalid_1's l1: 14.572\n",
      "[7650]\ttraining's l1: 12.4952\tvalid_1's l1: 14.5716\n",
      "[7700]\ttraining's l1: 12.4877\tvalid_1's l1: 14.5715\n",
      "[7750]\ttraining's l1: 12.4795\tvalid_1's l1: 14.5713\n",
      "[7800]\ttraining's l1: 12.471\tvalid_1's l1: 14.571\n",
      "[7850]\ttraining's l1: 12.4625\tvalid_1's l1: 14.5704\n",
      "[7900]\ttraining's l1: 12.4541\tvalid_1's l1: 14.5701\n",
      "[7950]\ttraining's l1: 12.4452\tvalid_1's l1: 14.57\n",
      "[8000]\ttraining's l1: 12.4363\tvalid_1's l1: 14.5701\n",
      "[8050]\ttraining's l1: 12.4272\tvalid_1's l1: 14.5701\n",
      "[8100]\ttraining's l1: 12.418\tvalid_1's l1: 14.5698\n",
      "[8150]\ttraining's l1: 12.4095\tvalid_1's l1: 14.5699\n",
      "[8200]\ttraining's l1: 12.4017\tvalid_1's l1: 14.5697\n",
      "[8250]\ttraining's l1: 12.3927\tvalid_1's l1: 14.5692\n",
      "[8300]\ttraining's l1: 12.3849\tvalid_1's l1: 14.569\n",
      "[8350]\ttraining's l1: 12.3788\tvalid_1's l1: 14.5691\n",
      "[8400]\ttraining's l1: 12.3724\tvalid_1's l1: 14.5693\n",
      "[8450]\ttraining's l1: 12.3654\tvalid_1's l1: 14.5693\n",
      "[8500]\ttraining's l1: 12.3584\tvalid_1's l1: 14.5695\n",
      "[8550]\ttraining's l1: 12.3525\tvalid_1's l1: 14.5695\n",
      "Early stopping, best iteration is:\n",
      "[8305]\ttraining's l1: 12.3841\tvalid_1's l1: 14.569\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's rmse: 35.756\ttraining's l1: 28.1683\tvalid_1's rmse: 36.0701\tvalid_1's l1: 28.3138\n",
      "[100]\ttraining's rmse: 30.9174\ttraining's l1: 24.1869\tvalid_1's rmse: 31.2617\tvalid_1's l1: 24.3463\n",
      "[150]\ttraining's rmse: 27.4798\ttraining's l1: 21.3587\tvalid_1's rmse: 27.8352\tvalid_1's l1: 21.5075\n",
      "[200]\ttraining's rmse: 25.0697\ttraining's l1: 19.3859\tvalid_1's rmse: 25.4212\tvalid_1's l1: 19.5347\n",
      "[250]\ttraining's rmse: 23.3948\ttraining's l1: 18.0323\tvalid_1's rmse: 23.7377\tvalid_1's l1: 18.1959\n",
      "[300]\ttraining's rmse: 22.2418\ttraining's l1: 17.1132\tvalid_1's rmse: 22.5707\tvalid_1's l1: 17.2888\n",
      "[350]\ttraining's rmse: 21.4382\ttraining's l1: 16.4825\tvalid_1's rmse: 21.7527\tvalid_1's l1: 16.6661\n",
      "[400]\ttraining's rmse: 20.8713\ttraining's l1: 16.0415\tvalid_1's rmse: 21.175\tvalid_1's l1: 16.2294\n",
      "[450]\ttraining's rmse: 20.4632\ttraining's l1: 15.7278\tvalid_1's rmse: 20.7578\tvalid_1's l1: 15.9193\n",
      "[500]\ttraining's rmse: 20.1605\ttraining's l1: 15.4966\tvalid_1's rmse: 20.4517\tvalid_1's l1: 15.692\n",
      "[550]\ttraining's rmse: 19.9253\ttraining's l1: 15.3215\tvalid_1's rmse: 20.2195\tvalid_1's l1: 15.5239\n",
      "[600]\ttraining's rmse: 19.7382\ttraining's l1: 15.1834\tvalid_1's rmse: 20.0365\tvalid_1's l1: 15.3896\n",
      "[650]\ttraining's rmse: 19.5843\ttraining's l1: 15.0699\tvalid_1's rmse: 19.8918\tvalid_1's l1: 15.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 19.4526\ttraining's l1: 14.9743\tvalid_1's rmse: 19.7723\tvalid_1's l1: 15.1929\n",
      "[750]\ttraining's rmse: 19.3392\ttraining's l1: 14.8909\tvalid_1's rmse: 19.6756\tvalid_1's l1: 15.1195\n",
      "[800]\ttraining's rmse: 19.2374\ttraining's l1: 14.8164\tvalid_1's rmse: 19.5948\tvalid_1's l1: 15.0581\n",
      "[850]\ttraining's rmse: 19.1465\ttraining's l1: 14.7503\tvalid_1's rmse: 19.5245\tvalid_1's l1: 15.0048\n",
      "[900]\ttraining's rmse: 19.0688\ttraining's l1: 14.6932\tvalid_1's rmse: 19.4714\tvalid_1's l1: 14.9645\n",
      "[950]\ttraining's rmse: 18.9967\ttraining's l1: 14.6412\tvalid_1's rmse: 19.4243\tvalid_1's l1: 14.9302\n",
      "[1000]\ttraining's rmse: 18.931\ttraining's l1: 14.5936\tvalid_1's rmse: 19.3822\tvalid_1's l1: 14.8984\n",
      "[1050]\ttraining's rmse: 18.8678\ttraining's l1: 14.5479\tvalid_1's rmse: 19.3444\tvalid_1's l1: 14.8699\n",
      "[1100]\ttraining's rmse: 18.8079\ttraining's l1: 14.5046\tvalid_1's rmse: 19.3089\tvalid_1's l1: 14.8429\n",
      "[1150]\ttraining's rmse: 18.7532\ttraining's l1: 14.4645\tvalid_1's rmse: 19.2806\tvalid_1's l1: 14.8215\n",
      "[1200]\ttraining's rmse: 18.6986\ttraining's l1: 14.4256\tvalid_1's rmse: 19.2506\tvalid_1's l1: 14.7981\n",
      "[1250]\ttraining's rmse: 18.6499\ttraining's l1: 14.3903\tvalid_1's rmse: 19.2298\tvalid_1's l1: 14.7806\n",
      "[1300]\ttraining's rmse: 18.6015\ttraining's l1: 14.3562\tvalid_1's rmse: 19.2063\tvalid_1's l1: 14.7644\n",
      "[1350]\ttraining's rmse: 18.5562\ttraining's l1: 14.3237\tvalid_1's rmse: 19.1862\tvalid_1's l1: 14.7498\n",
      "[1400]\ttraining's rmse: 18.5135\ttraining's l1: 14.2934\tvalid_1's rmse: 19.1679\tvalid_1's l1: 14.7364\n",
      "[1450]\ttraining's rmse: 18.4741\ttraining's l1: 14.2653\tvalid_1's rmse: 19.1533\tvalid_1's l1: 14.7255\n",
      "[1500]\ttraining's rmse: 18.4333\ttraining's l1: 14.2365\tvalid_1's rmse: 19.1378\tvalid_1's l1: 14.714\n",
      "[1550]\ttraining's rmse: 18.3934\ttraining's l1: 14.2077\tvalid_1's rmse: 19.1246\tvalid_1's l1: 14.7041\n",
      "[1600]\ttraining's rmse: 18.3564\ttraining's l1: 14.1816\tvalid_1's rmse: 19.1145\tvalid_1's l1: 14.6965\n",
      "[1650]\ttraining's rmse: 18.32\ttraining's l1: 14.1551\tvalid_1's rmse: 19.1016\tvalid_1's l1: 14.6873\n",
      "[1700]\ttraining's rmse: 18.2854\ttraining's l1: 14.1304\tvalid_1's rmse: 19.0936\tvalid_1's l1: 14.6816\n",
      "[1750]\ttraining's rmse: 18.2512\ttraining's l1: 14.1058\tvalid_1's rmse: 19.0835\tvalid_1's l1: 14.6748\n",
      "[1800]\ttraining's rmse: 18.2177\ttraining's l1: 14.0826\tvalid_1's rmse: 19.0761\tvalid_1's l1: 14.6695\n",
      "[1850]\ttraining's rmse: 18.1853\ttraining's l1: 14.0592\tvalid_1's rmse: 19.0687\tvalid_1's l1: 14.664\n",
      "[1900]\ttraining's rmse: 18.1536\ttraining's l1: 14.0362\tvalid_1's rmse: 19.0612\tvalid_1's l1: 14.6582\n",
      "[1950]\ttraining's rmse: 18.1223\ttraining's l1: 14.0137\tvalid_1's rmse: 19.0552\tvalid_1's l1: 14.6539\n",
      "[2000]\ttraining's rmse: 18.0924\ttraining's l1: 13.9921\tvalid_1's rmse: 19.0497\tvalid_1's l1: 14.6502\n",
      "[2050]\ttraining's rmse: 18.0626\ttraining's l1: 13.9704\tvalid_1's rmse: 19.0435\tvalid_1's l1: 14.6448\n",
      "[2100]\ttraining's rmse: 18.034\ttraining's l1: 13.9494\tvalid_1's rmse: 19.0366\tvalid_1's l1: 14.6394\n",
      "[2150]\ttraining's rmse: 18.0047\ttraining's l1: 13.9283\tvalid_1's rmse: 19.0313\tvalid_1's l1: 14.6355\n",
      "[2200]\ttraining's rmse: 17.9761\ttraining's l1: 13.9078\tvalid_1's rmse: 19.0269\tvalid_1's l1: 14.6325\n",
      "[2250]\ttraining's rmse: 17.9483\ttraining's l1: 13.8873\tvalid_1's rmse: 19.0231\tvalid_1's l1: 14.6295\n",
      "[2300]\ttraining's rmse: 17.9203\ttraining's l1: 13.8668\tvalid_1's rmse: 19.0181\tvalid_1's l1: 14.6256\n",
      "[2350]\ttraining's rmse: 17.8927\ttraining's l1: 13.8465\tvalid_1's rmse: 19.0134\tvalid_1's l1: 14.6216\n",
      "[2400]\ttraining's rmse: 17.866\ttraining's l1: 13.8266\tvalid_1's rmse: 19.0096\tvalid_1's l1: 14.6186\n",
      "[2450]\ttraining's rmse: 17.8391\ttraining's l1: 13.8069\tvalid_1's rmse: 19.0058\tvalid_1's l1: 14.6153\n",
      "[2500]\ttraining's rmse: 17.8128\ttraining's l1: 13.7879\tvalid_1's rmse: 19.0033\tvalid_1's l1: 14.6135\n",
      "[2550]\ttraining's rmse: 17.7864\ttraining's l1: 13.7685\tvalid_1's rmse: 18.9997\tvalid_1's l1: 14.6113\n",
      "[2600]\ttraining's rmse: 17.7599\ttraining's l1: 13.7492\tvalid_1's rmse: 18.9967\tvalid_1's l1: 14.6094\n",
      "[2650]\ttraining's rmse: 17.7336\ttraining's l1: 13.7307\tvalid_1's rmse: 18.9931\tvalid_1's l1: 14.6069\n",
      "[2700]\ttraining's rmse: 17.7083\ttraining's l1: 13.712\tvalid_1's rmse: 18.9902\tvalid_1's l1: 14.6045\n",
      "[2750]\ttraining's rmse: 17.6826\ttraining's l1: 13.6932\tvalid_1's rmse: 18.9865\tvalid_1's l1: 14.6017\n",
      "[2800]\ttraining's rmse: 17.657\ttraining's l1: 13.6745\tvalid_1's rmse: 18.9841\tvalid_1's l1: 14.5999\n",
      "[2850]\ttraining's rmse: 17.6318\ttraining's l1: 13.6557\tvalid_1's rmse: 18.9819\tvalid_1's l1: 14.5983\n",
      "[2900]\ttraining's rmse: 17.6075\ttraining's l1: 13.638\tvalid_1's rmse: 18.9789\tvalid_1's l1: 14.5957\n",
      "[2950]\ttraining's rmse: 17.5832\ttraining's l1: 13.62\tvalid_1's rmse: 18.9765\tvalid_1's l1: 14.594\n",
      "[3000]\ttraining's rmse: 17.559\ttraining's l1: 13.6022\tvalid_1's rmse: 18.9733\tvalid_1's l1: 14.5922\n",
      "[3050]\ttraining's rmse: 17.5344\ttraining's l1: 13.5842\tvalid_1's rmse: 18.9704\tvalid_1's l1: 14.59\n",
      "[3100]\ttraining's rmse: 17.511\ttraining's l1: 13.5663\tvalid_1's rmse: 18.9682\tvalid_1's l1: 14.5884\n",
      "[3150]\ttraining's rmse: 17.4874\ttraining's l1: 13.5486\tvalid_1's rmse: 18.9663\tvalid_1's l1: 14.5868\n",
      "[3200]\ttraining's rmse: 17.4647\ttraining's l1: 13.5318\tvalid_1's rmse: 18.9645\tvalid_1's l1: 14.5854\n",
      "[3250]\ttraining's rmse: 17.4414\ttraining's l1: 13.5145\tvalid_1's rmse: 18.9613\tvalid_1's l1: 14.5837\n",
      "[3300]\ttraining's rmse: 17.4196\ttraining's l1: 13.4982\tvalid_1's rmse: 18.9587\tvalid_1's l1: 14.582\n",
      "[3350]\ttraining's rmse: 17.3974\ttraining's l1: 13.4819\tvalid_1's rmse: 18.9578\tvalid_1's l1: 14.5814\n",
      "[3400]\ttraining's rmse: 17.3739\ttraining's l1: 13.4648\tvalid_1's rmse: 18.9552\tvalid_1's l1: 14.5796\n",
      "[3450]\ttraining's rmse: 17.35\ttraining's l1: 13.4474\tvalid_1's rmse: 18.9536\tvalid_1's l1: 14.5791\n",
      "[3500]\ttraining's rmse: 17.3276\ttraining's l1: 13.4309\tvalid_1's rmse: 18.9525\tvalid_1's l1: 14.5787\n",
      "[3550]\ttraining's rmse: 17.305\ttraining's l1: 13.4141\tvalid_1's rmse: 18.9508\tvalid_1's l1: 14.5781\n",
      "[3600]\ttraining's rmse: 17.2822\ttraining's l1: 13.3974\tvalid_1's rmse: 18.9485\tvalid_1's l1: 14.5771\n",
      "[3650]\ttraining's rmse: 17.2598\ttraining's l1: 13.3808\tvalid_1's rmse: 18.9477\tvalid_1's l1: 14.5765\n",
      "[3700]\ttraining's rmse: 17.239\ttraining's l1: 13.3652\tvalid_1's rmse: 18.9461\tvalid_1's l1: 14.5753\n",
      "[3750]\ttraining's rmse: 17.217\ttraining's l1: 13.3487\tvalid_1's rmse: 18.944\tvalid_1's l1: 14.5737\n",
      "[3800]\ttraining's rmse: 17.1956\ttraining's l1: 13.3331\tvalid_1's rmse: 18.9433\tvalid_1's l1: 14.5735\n",
      "[3850]\ttraining's rmse: 17.1733\ttraining's l1: 13.3168\tvalid_1's rmse: 18.9412\tvalid_1's l1: 14.572\n",
      "[3900]\ttraining's rmse: 17.1516\ttraining's l1: 13.3007\tvalid_1's rmse: 18.9395\tvalid_1's l1: 14.5711\n",
      "[3950]\ttraining's rmse: 17.1307\ttraining's l1: 13.2845\tvalid_1's rmse: 18.9383\tvalid_1's l1: 14.5703\n",
      "[4000]\ttraining's rmse: 17.1089\ttraining's l1: 13.2681\tvalid_1's rmse: 18.9366\tvalid_1's l1: 14.5688\n",
      "[4050]\ttraining's rmse: 17.088\ttraining's l1: 13.2528\tvalid_1's rmse: 18.9351\tvalid_1's l1: 14.5684\n",
      "[4100]\ttraining's rmse: 17.067\ttraining's l1: 13.2368\tvalid_1's rmse: 18.9335\tvalid_1's l1: 14.567\n",
      "[4150]\ttraining's rmse: 17.046\ttraining's l1: 13.2209\tvalid_1's rmse: 18.9324\tvalid_1's l1: 14.5662\n",
      "[4200]\ttraining's rmse: 17.0256\ttraining's l1: 13.2054\tvalid_1's rmse: 18.9307\tvalid_1's l1: 14.5652\n",
      "[4250]\ttraining's rmse: 17.0045\ttraining's l1: 13.1894\tvalid_1's rmse: 18.9303\tvalid_1's l1: 14.5647\n",
      "[4300]\ttraining's rmse: 16.9831\ttraining's l1: 13.1735\tvalid_1's rmse: 18.9295\tvalid_1's l1: 14.564\n",
      "[4350]\ttraining's rmse: 16.9625\ttraining's l1: 13.1577\tvalid_1's rmse: 18.9277\tvalid_1's l1: 14.5623\n",
      "[4400]\ttraining's rmse: 16.9414\ttraining's l1: 13.142\tvalid_1's rmse: 18.927\tvalid_1's l1: 14.5618\n",
      "[4450]\ttraining's rmse: 16.9213\ttraining's l1: 13.1269\tvalid_1's rmse: 18.9254\tvalid_1's l1: 14.5611\n",
      "[4500]\ttraining's rmse: 16.9015\ttraining's l1: 13.112\tvalid_1's rmse: 18.9241\tvalid_1's l1: 14.5606\n",
      "[4550]\ttraining's rmse: 16.8815\ttraining's l1: 13.0967\tvalid_1's rmse: 18.9228\tvalid_1's l1: 14.5595\n",
      "[4600]\ttraining's rmse: 16.8619\ttraining's l1: 13.0816\tvalid_1's rmse: 18.9207\tvalid_1's l1: 14.5577\n",
      "[4650]\ttraining's rmse: 16.8417\ttraining's l1: 13.066\tvalid_1's rmse: 18.9194\tvalid_1's l1: 14.556\n",
      "[4700]\ttraining's rmse: 16.822\ttraining's l1: 13.0508\tvalid_1's rmse: 18.9197\tvalid_1's l1: 14.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4750]\ttraining's rmse: 16.8025\ttraining's l1: 13.0358\tvalid_1's rmse: 18.9192\tvalid_1's l1: 14.5564\n",
      "[4800]\ttraining's rmse: 16.7823\ttraining's l1: 13.0206\tvalid_1's rmse: 18.919\tvalid_1's l1: 14.5564\n",
      "[4850]\ttraining's rmse: 16.7623\ttraining's l1: 13.0055\tvalid_1's rmse: 18.9192\tvalid_1's l1: 14.557\n",
      "[4900]\ttraining's rmse: 16.7415\ttraining's l1: 12.9902\tvalid_1's rmse: 18.9188\tvalid_1's l1: 14.5564\n",
      "Early stopping, best iteration is:\n",
      "[4664]\ttraining's rmse: 16.8362\ttraining's l1: 13.0618\tvalid_1's rmse: 18.9192\tvalid_1's l1: 14.5559\n",
      "****************************************************************************************************\n",
      "MAE Model 0.06423031041880967\n",
      "MSE Model 0.06428425554607979\n",
      "Merge Model12 0.06436476871165739\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's l1: 27.7966\tvalid_1's l1: 27.2938\n",
      "[100]\ttraining's l1: 24.0336\tvalid_1's l1: 23.6674\n",
      "[150]\ttraining's l1: 21.3562\tvalid_1's l1: 21.0897\n",
      "[200]\ttraining's l1: 19.4577\tvalid_1's l1: 19.2744\n",
      "[250]\ttraining's l1: 18.1242\tvalid_1's l1: 18.0239\n",
      "[300]\ttraining's l1: 17.1941\tvalid_1's l1: 17.1591\n",
      "[350]\ttraining's l1: 16.5412\tvalid_1's l1: 16.562\n",
      "[400]\ttraining's l1: 16.0723\tvalid_1's l1: 16.1403\n",
      "[450]\ttraining's l1: 15.7363\tvalid_1's l1: 15.8432\n",
      "[500]\ttraining's l1: 15.4901\tvalid_1's l1: 15.6287\n",
      "[550]\ttraining's l1: 15.2971\tvalid_1's l1: 15.4705\n",
      "[600]\ttraining's l1: 15.1449\tvalid_1's l1: 15.3484\n",
      "[650]\ttraining's l1: 15.0213\tvalid_1's l1: 15.2562\n",
      "[700]\ttraining's l1: 14.915\tvalid_1's l1: 15.1808\n",
      "[750]\ttraining's l1: 14.8218\tvalid_1's l1: 15.1186\n",
      "[800]\ttraining's l1: 14.7441\tvalid_1's l1: 15.0679\n",
      "[850]\ttraining's l1: 14.6741\tvalid_1's l1: 15.0275\n",
      "[900]\ttraining's l1: 14.6125\tvalid_1's l1: 14.9941\n",
      "[950]\ttraining's l1: 14.5566\tvalid_1's l1: 14.9653\n",
      "[1000]\ttraining's l1: 14.5069\tvalid_1's l1: 14.9418\n",
      "[1050]\ttraining's l1: 14.4597\tvalid_1's l1: 14.9216\n",
      "[1100]\ttraining's l1: 14.4149\tvalid_1's l1: 14.9037\n",
      "[1150]\ttraining's l1: 14.3745\tvalid_1's l1: 14.8894\n",
      "[1200]\ttraining's l1: 14.3373\tvalid_1's l1: 14.8764\n",
      "[1250]\ttraining's l1: 14.3001\tvalid_1's l1: 14.8631\n",
      "[1300]\ttraining's l1: 14.2653\tvalid_1's l1: 14.8507\n",
      "[1350]\ttraining's l1: 14.2331\tvalid_1's l1: 14.8418\n",
      "[1400]\ttraining's l1: 14.2013\tvalid_1's l1: 14.832\n",
      "[1450]\ttraining's l1: 14.1726\tvalid_1's l1: 14.8246\n",
      "[1500]\ttraining's l1: 14.143\tvalid_1's l1: 14.8172\n",
      "[1550]\ttraining's l1: 14.1153\tvalid_1's l1: 14.8106\n",
      "[1600]\ttraining's l1: 14.0882\tvalid_1's l1: 14.8047\n",
      "[1650]\ttraining's l1: 14.062\tvalid_1's l1: 14.7992\n",
      "[1700]\ttraining's l1: 14.0372\tvalid_1's l1: 14.7953\n",
      "[1750]\ttraining's l1: 14.0113\tvalid_1's l1: 14.7893\n",
      "[1800]\ttraining's l1: 13.9867\tvalid_1's l1: 14.7858\n",
      "[1850]\ttraining's l1: 13.9629\tvalid_1's l1: 14.7829\n",
      "[1900]\ttraining's l1: 13.9399\tvalid_1's l1: 14.7788\n",
      "[1950]\ttraining's l1: 13.9173\tvalid_1's l1: 14.7752\n",
      "[2000]\ttraining's l1: 13.8952\tvalid_1's l1: 14.7725\n",
      "[2050]\ttraining's l1: 13.8733\tvalid_1's l1: 14.7702\n",
      "[2100]\ttraining's l1: 13.8519\tvalid_1's l1: 14.7677\n",
      "[2150]\ttraining's l1: 13.8312\tvalid_1's l1: 14.7652\n",
      "[2200]\ttraining's l1: 13.8089\tvalid_1's l1: 14.7611\n",
      "[2250]\ttraining's l1: 13.788\tvalid_1's l1: 14.7587\n",
      "[2300]\ttraining's l1: 13.7682\tvalid_1's l1: 14.7557\n",
      "[2350]\ttraining's l1: 13.7479\tvalid_1's l1: 14.7532\n",
      "[2400]\ttraining's l1: 13.7292\tvalid_1's l1: 14.7522\n",
      "[2450]\ttraining's l1: 13.7097\tvalid_1's l1: 14.7505\n",
      "[2500]\ttraining's l1: 13.6903\tvalid_1's l1: 14.749\n",
      "[2550]\ttraining's l1: 13.6712\tvalid_1's l1: 14.7478\n",
      "[2600]\ttraining's l1: 13.6526\tvalid_1's l1: 14.7458\n",
      "[2650]\ttraining's l1: 13.6347\tvalid_1's l1: 14.7443\n",
      "[2700]\ttraining's l1: 13.6162\tvalid_1's l1: 14.7418\n",
      "[2750]\ttraining's l1: 13.5981\tvalid_1's l1: 14.7402\n",
      "[2800]\ttraining's l1: 13.5802\tvalid_1's l1: 14.7397\n",
      "[2850]\ttraining's l1: 13.5619\tvalid_1's l1: 14.7369\n",
      "[2900]\ttraining's l1: 13.5451\tvalid_1's l1: 14.7354\n",
      "[2950]\ttraining's l1: 13.5281\tvalid_1's l1: 14.7343\n",
      "[3000]\ttraining's l1: 13.511\tvalid_1's l1: 14.7333\n",
      "[3050]\ttraining's l1: 13.495\tvalid_1's l1: 14.7323\n",
      "[3100]\ttraining's l1: 13.4788\tvalid_1's l1: 14.7311\n",
      "[3150]\ttraining's l1: 13.4612\tvalid_1's l1: 14.7298\n",
      "[3200]\ttraining's l1: 13.4456\tvalid_1's l1: 14.7289\n",
      "[3250]\ttraining's l1: 13.4301\tvalid_1's l1: 14.7283\n",
      "[3300]\ttraining's l1: 13.4137\tvalid_1's l1: 14.7274\n",
      "[3350]\ttraining's l1: 13.3979\tvalid_1's l1: 14.7266\n",
      "[3400]\ttraining's l1: 13.3818\tvalid_1's l1: 14.7253\n",
      "[3450]\ttraining's l1: 13.3654\tvalid_1's l1: 14.7241\n",
      "[3500]\ttraining's l1: 13.3502\tvalid_1's l1: 14.7231\n",
      "[3550]\ttraining's l1: 13.3341\tvalid_1's l1: 14.722\n",
      "[3600]\ttraining's l1: 13.3204\tvalid_1's l1: 14.7213\n",
      "[3650]\ttraining's l1: 13.3048\tvalid_1's l1: 14.72\n",
      "[3700]\ttraining's l1: 13.2902\tvalid_1's l1: 14.7199\n",
      "[3750]\ttraining's l1: 13.2751\tvalid_1's l1: 14.7193\n",
      "[3800]\ttraining's l1: 13.2605\tvalid_1's l1: 14.7187\n",
      "[3850]\ttraining's l1: 13.2459\tvalid_1's l1: 14.7178\n",
      "[3900]\ttraining's l1: 13.2323\tvalid_1's l1: 14.7174\n",
      "[3950]\ttraining's l1: 13.2185\tvalid_1's l1: 14.7165\n",
      "[4000]\ttraining's l1: 13.2038\tvalid_1's l1: 14.7156\n",
      "[4050]\ttraining's l1: 13.1908\tvalid_1's l1: 14.7147\n",
      "[4100]\ttraining's l1: 13.1768\tvalid_1's l1: 14.7144\n",
      "[4150]\ttraining's l1: 13.1634\tvalid_1's l1: 14.7139\n",
      "[4200]\ttraining's l1: 13.1498\tvalid_1's l1: 14.7131\n",
      "[4250]\ttraining's l1: 13.1368\tvalid_1's l1: 14.7131\n",
      "[4300]\ttraining's l1: 13.1242\tvalid_1's l1: 14.7132\n",
      "[4350]\ttraining's l1: 13.1116\tvalid_1's l1: 14.7126\n",
      "[4400]\ttraining's l1: 13.099\tvalid_1's l1: 14.7121\n",
      "[4450]\ttraining's l1: 13.0866\tvalid_1's l1: 14.7115\n",
      "[4500]\ttraining's l1: 13.0726\tvalid_1's l1: 14.7111\n",
      "[4550]\ttraining's l1: 13.0607\tvalid_1's l1: 14.7112\n",
      "[4600]\ttraining's l1: 13.0478\tvalid_1's l1: 14.7108\n",
      "[4650]\ttraining's l1: 13.0352\tvalid_1's l1: 14.71\n",
      "[4700]\ttraining's l1: 13.0211\tvalid_1's l1: 14.7089\n",
      "[4750]\ttraining's l1: 13.0082\tvalid_1's l1: 14.708\n",
      "[4800]\ttraining's l1: 12.9958\tvalid_1's l1: 14.7075\n",
      "[4850]\ttraining's l1: 12.9832\tvalid_1's l1: 14.7074\n",
      "[4900]\ttraining's l1: 12.9721\tvalid_1's l1: 14.707\n",
      "[4950]\ttraining's l1: 12.96\tvalid_1's l1: 14.7069\n",
      "[5000]\ttraining's l1: 12.9471\tvalid_1's l1: 14.7067\n",
      "[5050]\ttraining's l1: 12.9355\tvalid_1's l1: 14.7067\n",
      "[5100]\ttraining's l1: 12.9246\tvalid_1's l1: 14.7075\n",
      "[5150]\ttraining's l1: 12.9144\tvalid_1's l1: 14.7079\n",
      "[5200]\ttraining's l1: 12.9064\tvalid_1's l1: 14.7076\n",
      "[5250]\ttraining's l1: 12.897\tvalid_1's l1: 14.7076\n",
      "Early stopping, best iteration is:\n",
      "[5020]\ttraining's l1: 12.9425\tvalid_1's l1: 14.7064\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's rmse: 35.9109\ttraining's l1: 28.276\tvalid_1's rmse: 35.3376\tvalid_1's l1: 27.8156\n",
      "[100]\ttraining's rmse: 31.0333\ttraining's l1: 24.2605\tvalid_1's rmse: 30.6121\tvalid_1's l1: 23.9245\n",
      "[150]\ttraining's rmse: 27.5635\ttraining's l1: 21.4011\tvalid_1's rmse: 27.271\tvalid_1's l1: 21.1803\n",
      "[200]\ttraining's rmse: 25.121\ttraining's l1: 19.4013\tvalid_1's rmse: 24.9409\tvalid_1's l1: 19.2745\n",
      "[250]\ttraining's rmse: 23.4185\ttraining's l1: 18.0303\tvalid_1's rmse: 23.3368\tvalid_1's l1: 17.9806\n",
      "[300]\ttraining's rmse: 22.2402\ttraining's l1: 17.095\tvalid_1's rmse: 22.2497\tvalid_1's l1: 17.1162\n",
      "[350]\ttraining's rmse: 21.4188\ttraining's l1: 16.4544\tvalid_1's rmse: 21.5069\tvalid_1's l1: 16.5229\n",
      "[400]\ttraining's rmse: 20.8355\ttraining's l1: 16.0065\tvalid_1's rmse: 20.9952\tvalid_1's l1: 16.112\n",
      "[450]\ttraining's rmse: 20.414\ttraining's l1: 15.6884\tvalid_1's rmse: 20.6387\tvalid_1's l1: 15.826\n",
      "[500]\ttraining's rmse: 20.0988\ttraining's l1: 15.4542\tvalid_1's rmse: 20.3814\tvalid_1's l1: 15.6235\n",
      "[550]\ttraining's rmse: 19.8575\ttraining's l1: 15.2757\tvalid_1's rmse: 20.1917\tvalid_1's l1: 15.479\n",
      "[600]\ttraining's rmse: 19.6619\ttraining's l1: 15.132\tvalid_1's rmse: 20.047\tvalid_1's l1: 15.3721\n",
      "[650]\ttraining's rmse: 19.5045\ttraining's l1: 15.0166\tvalid_1's rmse: 19.9381\tvalid_1's l1: 15.2898\n",
      "[700]\ttraining's rmse: 19.3688\ttraining's l1: 14.9191\tvalid_1's rmse: 19.8468\tvalid_1's l1: 15.2229\n",
      "[750]\ttraining's rmse: 19.2508\ttraining's l1: 14.8348\tvalid_1's rmse: 19.773\tvalid_1's l1: 15.1679\n",
      "[800]\ttraining's rmse: 19.1491\ttraining's l1: 14.7606\tvalid_1's rmse: 19.7126\tvalid_1's l1: 15.1218\n",
      "[850]\ttraining's rmse: 19.0577\ttraining's l1: 14.6944\tvalid_1's rmse: 19.6611\tvalid_1's l1: 15.0812\n",
      "[900]\ttraining's rmse: 18.979\ttraining's l1: 14.6377\tvalid_1's rmse: 19.6215\tvalid_1's l1: 15.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950]\ttraining's rmse: 18.9043\ttraining's l1: 14.5837\tvalid_1's rmse: 19.5851\tvalid_1's l1: 15.023\n",
      "[1000]\ttraining's rmse: 18.8358\ttraining's l1: 14.5349\tvalid_1's rmse: 19.5529\tvalid_1's l1: 14.9974\n",
      "[1050]\ttraining's rmse: 18.7731\ttraining's l1: 14.4892\tvalid_1's rmse: 19.5264\tvalid_1's l1: 14.9757\n",
      "[1100]\ttraining's rmse: 18.7113\ttraining's l1: 14.4456\tvalid_1's rmse: 19.499\tvalid_1's l1: 14.9545\n",
      "[1150]\ttraining's rmse: 18.6542\ttraining's l1: 14.4047\tvalid_1's rmse: 19.4756\tvalid_1's l1: 14.9366\n",
      "[1200]\ttraining's rmse: 18.5999\ttraining's l1: 14.3669\tvalid_1's rmse: 19.4564\tvalid_1's l1: 14.9228\n",
      "[1250]\ttraining's rmse: 18.5499\ttraining's l1: 14.3313\tvalid_1's rmse: 19.4391\tvalid_1's l1: 14.9097\n",
      "[1300]\ttraining's rmse: 18.5027\ttraining's l1: 14.2979\tvalid_1's rmse: 19.4253\tvalid_1's l1: 14.8986\n",
      "[1350]\ttraining's rmse: 18.456\ttraining's l1: 14.2651\tvalid_1's rmse: 19.412\tvalid_1's l1: 14.8884\n",
      "[1400]\ttraining's rmse: 18.4124\ttraining's l1: 14.2341\tvalid_1's rmse: 19.4009\tvalid_1's l1: 14.8792\n",
      "[1450]\ttraining's rmse: 18.3714\ttraining's l1: 14.205\tvalid_1's rmse: 19.3906\tvalid_1's l1: 14.8713\n",
      "[1500]\ttraining's rmse: 18.332\ttraining's l1: 14.1774\tvalid_1's rmse: 19.3826\tvalid_1's l1: 14.8651\n",
      "[1550]\ttraining's rmse: 18.2924\ttraining's l1: 14.1497\tvalid_1's rmse: 19.374\tvalid_1's l1: 14.8583\n",
      "[1600]\ttraining's rmse: 18.256\ttraining's l1: 14.1236\tvalid_1's rmse: 19.3691\tvalid_1's l1: 14.8535\n",
      "[1650]\ttraining's rmse: 18.2205\ttraining's l1: 14.0981\tvalid_1's rmse: 19.3639\tvalid_1's l1: 14.8485\n",
      "[1700]\ttraining's rmse: 18.1853\ttraining's l1: 14.0726\tvalid_1's rmse: 19.3582\tvalid_1's l1: 14.8436\n",
      "[1750]\ttraining's rmse: 18.1517\ttraining's l1: 14.0485\tvalid_1's rmse: 19.3532\tvalid_1's l1: 14.8385\n",
      "[1800]\ttraining's rmse: 18.1185\ttraining's l1: 14.0244\tvalid_1's rmse: 19.3491\tvalid_1's l1: 14.8343\n",
      "[1850]\ttraining's rmse: 18.0858\ttraining's l1: 14.0013\tvalid_1's rmse: 19.3461\tvalid_1's l1: 14.8313\n",
      "[1900]\ttraining's rmse: 18.0542\ttraining's l1: 13.9785\tvalid_1's rmse: 19.3436\tvalid_1's l1: 14.8283\n",
      "[1950]\ttraining's rmse: 18.0228\ttraining's l1: 13.9558\tvalid_1's rmse: 19.3396\tvalid_1's l1: 14.8253\n",
      "[2000]\ttraining's rmse: 17.9916\ttraining's l1: 13.9335\tvalid_1's rmse: 19.3357\tvalid_1's l1: 14.8221\n",
      "[2050]\ttraining's rmse: 17.9625\ttraining's l1: 13.9123\tvalid_1's rmse: 19.3331\tvalid_1's l1: 14.8198\n",
      "[2100]\ttraining's rmse: 17.9325\ttraining's l1: 13.8908\tvalid_1's rmse: 19.3304\tvalid_1's l1: 14.8173\n",
      "[2150]\ttraining's rmse: 17.9022\ttraining's l1: 13.8692\tvalid_1's rmse: 19.3277\tvalid_1's l1: 14.8153\n",
      "[2200]\ttraining's rmse: 17.8727\ttraining's l1: 13.8481\tvalid_1's rmse: 19.3248\tvalid_1's l1: 14.8123\n",
      "[2250]\ttraining's rmse: 17.8438\ttraining's l1: 13.8272\tvalid_1's rmse: 19.322\tvalid_1's l1: 14.8101\n",
      "[2300]\ttraining's rmse: 17.8156\ttraining's l1: 13.8067\tvalid_1's rmse: 19.3195\tvalid_1's l1: 14.808\n",
      "[2350]\ttraining's rmse: 17.787\ttraining's l1: 13.7858\tvalid_1's rmse: 19.3172\tvalid_1's l1: 14.806\n",
      "[2400]\ttraining's rmse: 17.7599\ttraining's l1: 13.7653\tvalid_1's rmse: 19.3152\tvalid_1's l1: 14.804\n",
      "[2450]\ttraining's rmse: 17.7325\ttraining's l1: 13.7457\tvalid_1's rmse: 19.3133\tvalid_1's l1: 14.8024\n",
      "[2500]\ttraining's rmse: 17.7065\ttraining's l1: 13.7268\tvalid_1's rmse: 19.3134\tvalid_1's l1: 14.8022\n",
      "[2550]\ttraining's rmse: 17.6797\ttraining's l1: 13.7071\tvalid_1's rmse: 19.3118\tvalid_1's l1: 14.8007\n",
      "[2600]\ttraining's rmse: 17.6544\ttraining's l1: 13.6879\tvalid_1's rmse: 19.3098\tvalid_1's l1: 14.7988\n",
      "[2650]\ttraining's rmse: 17.6273\ttraining's l1: 13.6688\tvalid_1's rmse: 19.308\tvalid_1's l1: 14.7972\n",
      "[2700]\ttraining's rmse: 17.6015\ttraining's l1: 13.6497\tvalid_1's rmse: 19.3058\tvalid_1's l1: 14.7954\n",
      "[2750]\ttraining's rmse: 17.5768\ttraining's l1: 13.6315\tvalid_1's rmse: 19.3049\tvalid_1's l1: 14.7946\n",
      "[2800]\ttraining's rmse: 17.5512\ttraining's l1: 13.6129\tvalid_1's rmse: 19.3033\tvalid_1's l1: 14.7933\n",
      "[2850]\ttraining's rmse: 17.5265\ttraining's l1: 13.5946\tvalid_1's rmse: 19.3024\tvalid_1's l1: 14.7924\n",
      "[2900]\ttraining's rmse: 17.5009\ttraining's l1: 13.5759\tvalid_1's rmse: 19.3001\tvalid_1's l1: 14.791\n",
      "[2950]\ttraining's rmse: 17.4772\ttraining's l1: 13.5581\tvalid_1's rmse: 19.2992\tvalid_1's l1: 14.7899\n",
      "[3000]\ttraining's rmse: 17.4522\ttraining's l1: 13.5396\tvalid_1's rmse: 19.2979\tvalid_1's l1: 14.7882\n",
      "[3050]\ttraining's rmse: 17.4271\ttraining's l1: 13.5212\tvalid_1's rmse: 19.2972\tvalid_1's l1: 14.7869\n",
      "[3100]\ttraining's rmse: 17.4028\ttraining's l1: 13.5033\tvalid_1's rmse: 19.2969\tvalid_1's l1: 14.7866\n",
      "[3150]\ttraining's rmse: 17.379\ttraining's l1: 13.4856\tvalid_1's rmse: 19.297\tvalid_1's l1: 14.7856\n",
      "[3200]\ttraining's rmse: 17.3557\ttraining's l1: 13.4679\tvalid_1's rmse: 19.2958\tvalid_1's l1: 14.7841\n",
      "[3250]\ttraining's rmse: 17.3326\ttraining's l1: 13.4507\tvalid_1's rmse: 19.2955\tvalid_1's l1: 14.7839\n",
      "[3300]\ttraining's rmse: 17.3084\ttraining's l1: 13.4329\tvalid_1's rmse: 19.2944\tvalid_1's l1: 14.783\n",
      "[3350]\ttraining's rmse: 17.2853\ttraining's l1: 13.416\tvalid_1's rmse: 19.2938\tvalid_1's l1: 14.7821\n",
      "[3400]\ttraining's rmse: 17.262\ttraining's l1: 13.3988\tvalid_1's rmse: 19.2922\tvalid_1's l1: 14.7808\n",
      "[3450]\ttraining's rmse: 17.2388\ttraining's l1: 13.3817\tvalid_1's rmse: 19.2911\tvalid_1's l1: 14.7799\n",
      "[3500]\ttraining's rmse: 17.2155\ttraining's l1: 13.3646\tvalid_1's rmse: 19.2913\tvalid_1's l1: 14.7799\n",
      "[3550]\ttraining's rmse: 17.1923\ttraining's l1: 13.3473\tvalid_1's rmse: 19.2905\tvalid_1's l1: 14.7787\n",
      "[3600]\ttraining's rmse: 17.1699\ttraining's l1: 13.3304\tvalid_1's rmse: 19.2905\tvalid_1's l1: 14.7783\n",
      "[3650]\ttraining's rmse: 17.1472\ttraining's l1: 13.3133\tvalid_1's rmse: 19.291\tvalid_1's l1: 14.7779\n",
      "[3700]\ttraining's rmse: 17.1253\ttraining's l1: 13.2972\tvalid_1's rmse: 19.2911\tvalid_1's l1: 14.7773\n",
      "[3750]\ttraining's rmse: 17.1022\ttraining's l1: 13.2801\tvalid_1's rmse: 19.2899\tvalid_1's l1: 14.7763\n",
      "[3800]\ttraining's rmse: 17.0815\ttraining's l1: 13.264\tvalid_1's rmse: 19.2891\tvalid_1's l1: 14.7755\n",
      "[3850]\ttraining's rmse: 17.0593\ttraining's l1: 13.2477\tvalid_1's rmse: 19.2889\tvalid_1's l1: 14.7748\n",
      "[3900]\ttraining's rmse: 17.0379\ttraining's l1: 13.2316\tvalid_1's rmse: 19.2885\tvalid_1's l1: 14.7742\n",
      "[3950]\ttraining's rmse: 17.0169\ttraining's l1: 13.2153\tvalid_1's rmse: 19.2886\tvalid_1's l1: 14.7737\n",
      "[4000]\ttraining's rmse: 16.9949\ttraining's l1: 13.1988\tvalid_1's rmse: 19.2885\tvalid_1's l1: 14.7738\n",
      "[4050]\ttraining's rmse: 16.9736\ttraining's l1: 13.1828\tvalid_1's rmse: 19.2885\tvalid_1's l1: 14.7738\n",
      "[4100]\ttraining's rmse: 16.9511\ttraining's l1: 13.1664\tvalid_1's rmse: 19.2888\tvalid_1's l1: 14.7739\n",
      "[4150]\ttraining's rmse: 16.9289\ttraining's l1: 13.1502\tvalid_1's rmse: 19.2889\tvalid_1's l1: 14.7736\n",
      "[4200]\ttraining's rmse: 16.9086\ttraining's l1: 13.1346\tvalid_1's rmse: 19.2886\tvalid_1's l1: 14.773\n",
      "Early stopping, best iteration is:\n",
      "[3991]\ttraining's rmse: 16.9986\ttraining's l1: 13.2015\tvalid_1's rmse: 19.2881\tvalid_1's l1: 14.7734\n",
      "****************************************************************************************************\n",
      "MAE Model 0.06366839937186383\n",
      "MSE Model 0.06339797911506088\n",
      "Merge Model12 0.06372137136424065\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's l1: 27.6643\tvalid_1's l1: 27.8689\n",
      "[100]\ttraining's l1: 23.9192\tvalid_1's l1: 24.143\n",
      "[150]\ttraining's l1: 21.2474\tvalid_1's l1: 21.5081\n",
      "[200]\ttraining's l1: 19.3569\tvalid_1's l1: 19.6649\n",
      "[250]\ttraining's l1: 18.0308\tvalid_1's l1: 18.3834\n",
      "[300]\ttraining's l1: 17.114\tvalid_1's l1: 17.4819\n",
      "[350]\ttraining's l1: 16.4696\tvalid_1's l1: 16.8456\n",
      "[400]\ttraining's l1: 16.0109\tvalid_1's l1: 16.3987\n",
      "[450]\ttraining's l1: 15.6768\tvalid_1's l1: 16.0888\n",
      "[500]\ttraining's l1: 15.4276\tvalid_1's l1: 15.8683\n",
      "[550]\ttraining's l1: 15.2368\tvalid_1's l1: 15.7091\n",
      "[600]\ttraining's l1: 15.0875\tvalid_1's l1: 15.5882\n",
      "[650]\ttraining's l1: 14.9655\tvalid_1's l1: 15.4918\n",
      "[700]\ttraining's l1: 14.8551\tvalid_1's l1: 15.4049\n",
      "[750]\ttraining's l1: 14.7658\tvalid_1's l1: 15.3401\n",
      "[800]\ttraining's l1: 14.6898\tvalid_1's l1: 15.2871\n",
      "[850]\ttraining's l1: 14.6228\tvalid_1's l1: 15.2426\n",
      "[900]\ttraining's l1: 14.5642\tvalid_1's l1: 15.2048\n",
      "[950]\ttraining's l1: 14.5105\tvalid_1's l1: 15.1721\n",
      "[1000]\ttraining's l1: 14.4602\tvalid_1's l1: 15.1427\n",
      "[1050]\ttraining's l1: 14.4142\tvalid_1's l1: 15.1178\n",
      "[1100]\ttraining's l1: 14.3739\tvalid_1's l1: 15.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1150]\ttraining's l1: 14.3356\tvalid_1's l1: 15.0771\n",
      "[1200]\ttraining's l1: 14.2988\tvalid_1's l1: 15.0583\n",
      "[1250]\ttraining's l1: 14.2645\tvalid_1's l1: 15.0439\n",
      "[1300]\ttraining's l1: 14.2312\tvalid_1's l1: 15.0305\n",
      "[1350]\ttraining's l1: 14.1999\tvalid_1's l1: 15.0192\n",
      "[1400]\ttraining's l1: 14.1695\tvalid_1's l1: 15.0088\n",
      "[1450]\ttraining's l1: 14.1398\tvalid_1's l1: 14.9992\n",
      "[1500]\ttraining's l1: 14.112\tvalid_1's l1: 14.9915\n",
      "[1550]\ttraining's l1: 14.0847\tvalid_1's l1: 14.9834\n",
      "[1600]\ttraining's l1: 14.0585\tvalid_1's l1: 14.9768\n",
      "[1650]\ttraining's l1: 14.0332\tvalid_1's l1: 14.9716\n",
      "[1700]\ttraining's l1: 14.0081\tvalid_1's l1: 14.9653\n",
      "[1750]\ttraining's l1: 13.9837\tvalid_1's l1: 14.9591\n",
      "[1800]\ttraining's l1: 13.9599\tvalid_1's l1: 14.954\n",
      "[1850]\ttraining's l1: 13.9375\tvalid_1's l1: 14.9512\n",
      "[1900]\ttraining's l1: 13.9158\tvalid_1's l1: 14.9474\n",
      "[1950]\ttraining's l1: 13.8942\tvalid_1's l1: 14.9435\n",
      "[2000]\ttraining's l1: 13.8735\tvalid_1's l1: 14.9405\n",
      "[2050]\ttraining's l1: 13.8539\tvalid_1's l1: 14.9386\n",
      "[2100]\ttraining's l1: 13.8348\tvalid_1's l1: 14.9364\n",
      "[2150]\ttraining's l1: 13.8137\tvalid_1's l1: 14.9327\n",
      "[2200]\ttraining's l1: 13.7933\tvalid_1's l1: 14.9308\n",
      "[2250]\ttraining's l1: 13.7714\tvalid_1's l1: 14.9267\n",
      "[2300]\ttraining's l1: 13.7515\tvalid_1's l1: 14.9238\n",
      "[2350]\ttraining's l1: 13.7321\tvalid_1's l1: 14.9211\n",
      "[2400]\ttraining's l1: 13.7118\tvalid_1's l1: 14.9184\n",
      "[2450]\ttraining's l1: 13.692\tvalid_1's l1: 14.9153\n",
      "[2500]\ttraining's l1: 13.6736\tvalid_1's l1: 14.914\n",
      "[2550]\ttraining's l1: 13.6542\tvalid_1's l1: 14.9112\n",
      "[2600]\ttraining's l1: 13.6361\tvalid_1's l1: 14.9092\n",
      "[2650]\ttraining's l1: 13.6172\tvalid_1's l1: 14.9057\n",
      "[2700]\ttraining's l1: 13.5987\tvalid_1's l1: 14.9029\n",
      "[2750]\ttraining's l1: 13.5796\tvalid_1's l1: 14.8997\n",
      "[2800]\ttraining's l1: 13.5615\tvalid_1's l1: 14.8978\n",
      "[2850]\ttraining's l1: 13.5443\tvalid_1's l1: 14.8958\n",
      "[2900]\ttraining's l1: 13.5268\tvalid_1's l1: 14.8936\n",
      "[2950]\ttraining's l1: 13.5101\tvalid_1's l1: 14.8922\n",
      "[3000]\ttraining's l1: 13.4932\tvalid_1's l1: 14.891\n",
      "[3050]\ttraining's l1: 13.4784\tvalid_1's l1: 14.8901\n",
      "[3100]\ttraining's l1: 13.462\tvalid_1's l1: 14.8884\n",
      "[3150]\ttraining's l1: 13.4457\tvalid_1's l1: 14.8866\n",
      "[3200]\ttraining's l1: 13.4286\tvalid_1's l1: 14.8844\n",
      "[3250]\ttraining's l1: 13.4123\tvalid_1's l1: 14.8827\n",
      "[3300]\ttraining's l1: 13.3954\tvalid_1's l1: 14.8804\n",
      "[3350]\ttraining's l1: 13.3801\tvalid_1's l1: 14.8788\n",
      "[3400]\ttraining's l1: 13.3648\tvalid_1's l1: 14.8768\n",
      "[3450]\ttraining's l1: 13.3503\tvalid_1's l1: 14.8756\n",
      "[3500]\ttraining's l1: 13.3355\tvalid_1's l1: 14.8747\n",
      "[3550]\ttraining's l1: 13.3186\tvalid_1's l1: 14.8729\n",
      "[3600]\ttraining's l1: 13.3038\tvalid_1's l1: 14.8721\n",
      "[3650]\ttraining's l1: 13.2881\tvalid_1's l1: 14.8701\n",
      "[3700]\ttraining's l1: 13.2737\tvalid_1's l1: 14.8694\n",
      "[3750]\ttraining's l1: 13.2595\tvalid_1's l1: 14.8679\n",
      "[3800]\ttraining's l1: 13.2458\tvalid_1's l1: 14.867\n",
      "[3850]\ttraining's l1: 13.231\tvalid_1's l1: 14.866\n",
      "[3900]\ttraining's l1: 13.2187\tvalid_1's l1: 14.8654\n",
      "[3950]\ttraining's l1: 13.2049\tvalid_1's l1: 14.8638\n",
      "[4000]\ttraining's l1: 13.1914\tvalid_1's l1: 14.8628\n",
      "[4050]\ttraining's l1: 13.1776\tvalid_1's l1: 14.8616\n",
      "[4100]\ttraining's l1: 13.1643\tvalid_1's l1: 14.8609\n",
      "[4150]\ttraining's l1: 13.1501\tvalid_1's l1: 14.8601\n",
      "[4200]\ttraining's l1: 13.1372\tvalid_1's l1: 14.8598\n",
      "[4250]\ttraining's l1: 13.1248\tvalid_1's l1: 14.8592\n",
      "[4300]\ttraining's l1: 13.1113\tvalid_1's l1: 14.8585\n",
      "[4350]\ttraining's l1: 13.0988\tvalid_1's l1: 14.8574\n",
      "[4400]\ttraining's l1: 13.087\tvalid_1's l1: 14.8567\n",
      "[4450]\ttraining's l1: 13.0757\tvalid_1's l1: 14.8568\n",
      "[4500]\ttraining's l1: 13.0627\tvalid_1's l1: 14.8561\n",
      "[4550]\ttraining's l1: 13.0502\tvalid_1's l1: 14.8555\n",
      "[4600]\ttraining's l1: 13.0396\tvalid_1's l1: 14.8557\n",
      "[4650]\ttraining's l1: 13.0286\tvalid_1's l1: 14.8554\n",
      "[4700]\ttraining's l1: 13.0175\tvalid_1's l1: 14.855\n",
      "[4750]\ttraining's l1: 13.0059\tvalid_1's l1: 14.8549\n",
      "[4800]\ttraining's l1: 12.9949\tvalid_1's l1: 14.8546\n",
      "[4850]\ttraining's l1: 12.9851\tvalid_1's l1: 14.8541\n",
      "[4900]\ttraining's l1: 12.9734\tvalid_1's l1: 14.8537\n",
      "[4950]\ttraining's l1: 12.9617\tvalid_1's l1: 14.8533\n",
      "[5000]\ttraining's l1: 12.9506\tvalid_1's l1: 14.8528\n",
      "[5050]\ttraining's l1: 12.9391\tvalid_1's l1: 14.8521\n",
      "[5100]\ttraining's l1: 12.9269\tvalid_1's l1: 14.8514\n",
      "[5150]\ttraining's l1: 12.9147\tvalid_1's l1: 14.8507\n",
      "[5200]\ttraining's l1: 12.9026\tvalid_1's l1: 14.8507\n",
      "[5250]\ttraining's l1: 12.8896\tvalid_1's l1: 14.8501\n",
      "[5300]\ttraining's l1: 12.8774\tvalid_1's l1: 14.8491\n",
      "[5350]\ttraining's l1: 12.865\tvalid_1's l1: 14.8491\n",
      "[5400]\ttraining's l1: 12.8537\tvalid_1's l1: 14.8485\n",
      "[5450]\ttraining's l1: 12.8419\tvalid_1's l1: 14.848\n",
      "[5500]\ttraining's l1: 12.83\tvalid_1's l1: 14.8476\n",
      "[5550]\ttraining's l1: 12.8183\tvalid_1's l1: 14.8471\n",
      "[5600]\ttraining's l1: 12.8072\tvalid_1's l1: 14.8463\n",
      "[5650]\ttraining's l1: 12.7958\tvalid_1's l1: 14.8459\n",
      "[5700]\ttraining's l1: 12.7852\tvalid_1's l1: 14.8452\n",
      "[5750]\ttraining's l1: 12.7745\tvalid_1's l1: 14.8456\n",
      "[5800]\ttraining's l1: 12.7636\tvalid_1's l1: 14.8454\n",
      "[5850]\ttraining's l1: 12.7542\tvalid_1's l1: 14.8451\n",
      "[5900]\ttraining's l1: 12.7438\tvalid_1's l1: 14.8448\n",
      "[5950]\ttraining's l1: 12.7338\tvalid_1's l1: 14.8449\n",
      "[6000]\ttraining's l1: 12.7228\tvalid_1's l1: 14.844\n",
      "[6050]\ttraining's l1: 12.7115\tvalid_1's l1: 14.8437\n",
      "[6100]\ttraining's l1: 12.7001\tvalid_1's l1: 14.844\n",
      "[6150]\ttraining's l1: 12.6887\tvalid_1's l1: 14.8438\n",
      "[6200]\ttraining's l1: 12.6797\tvalid_1's l1: 14.8439\n",
      "[6250]\ttraining's l1: 12.6697\tvalid_1's l1: 14.8434\n",
      "[6300]\ttraining's l1: 12.6604\tvalid_1's l1: 14.843\n",
      "[6350]\ttraining's l1: 12.6501\tvalid_1's l1: 14.8423\n",
      "[6400]\ttraining's l1: 12.6392\tvalid_1's l1: 14.8421\n",
      "[6450]\ttraining's l1: 12.6294\tvalid_1's l1: 14.8419\n",
      "[6500]\ttraining's l1: 12.6193\tvalid_1's l1: 14.8415\n",
      "[6550]\ttraining's l1: 12.6092\tvalid_1's l1: 14.8414\n",
      "[6600]\ttraining's l1: 12.5991\tvalid_1's l1: 14.8414\n",
      "[6650]\ttraining's l1: 12.589\tvalid_1's l1: 14.8413\n",
      "[6700]\ttraining's l1: 12.579\tvalid_1's l1: 14.8407\n",
      "[6750]\ttraining's l1: 12.5691\tvalid_1's l1: 14.8403\n",
      "[6800]\ttraining's l1: 12.5609\tvalid_1's l1: 14.8402\n",
      "[6850]\ttraining's l1: 12.5508\tvalid_1's l1: 14.8397\n",
      "[6900]\ttraining's l1: 12.544\tvalid_1's l1: 14.839\n",
      "[6950]\ttraining's l1: 12.5383\tvalid_1's l1: 14.8391\n",
      "[7000]\ttraining's l1: 12.5305\tvalid_1's l1: 14.8392\n",
      "[7050]\ttraining's l1: 12.5234\tvalid_1's l1: 14.8389\n",
      "[7100]\ttraining's l1: 12.5168\tvalid_1's l1: 14.8388\n",
      "[7150]\ttraining's l1: 12.5108\tvalid_1's l1: 14.8392\n",
      "[7200]\ttraining's l1: 12.5036\tvalid_1's l1: 14.8387\n",
      "[7250]\ttraining's l1: 12.4969\tvalid_1's l1: 14.8384\n",
      "[7300]\ttraining's l1: 12.49\tvalid_1's l1: 14.8381\n",
      "[7350]\ttraining's l1: 12.4834\tvalid_1's l1: 14.8377\n",
      "[7400]\ttraining's l1: 12.4775\tvalid_1's l1: 14.8376\n",
      "[7450]\ttraining's l1: 12.4703\tvalid_1's l1: 14.8377\n",
      "[7500]\ttraining's l1: 12.4636\tvalid_1's l1: 14.8375\n",
      "[7550]\ttraining's l1: 12.4575\tvalid_1's l1: 14.8372\n",
      "[7600]\ttraining's l1: 12.4518\tvalid_1's l1: 14.837\n",
      "[7650]\ttraining's l1: 12.4465\tvalid_1's l1: 14.8372\n",
      "[7700]\ttraining's l1: 12.4423\tvalid_1's l1: 14.8371\n",
      "[7750]\ttraining's l1: 12.437\tvalid_1's l1: 14.8373\n",
      "[7800]\ttraining's l1: 12.4325\tvalid_1's l1: 14.8374\n",
      "[7850]\ttraining's l1: 12.4265\tvalid_1's l1: 14.8371\n",
      "Early stopping, best iteration is:\n",
      "[7622]\ttraining's l1: 12.4494\tvalid_1's l1: 14.8369\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\ttraining's rmse: 35.7587\ttraining's l1: 28.1169\tvalid_1's rmse: 35.9259\tvalid_1's l1: 28.2191\n",
      "[100]\ttraining's rmse: 30.9054\ttraining's l1: 24.1317\tvalid_1's rmse: 31.0861\tvalid_1's l1: 24.224\n",
      "[150]\ttraining's rmse: 27.4524\ttraining's l1: 21.2965\tvalid_1's rmse: 27.6733\tvalid_1's l1: 21.4138\n",
      "[200]\ttraining's rmse: 25.0267\ttraining's l1: 19.3182\tvalid_1's rmse: 25.2995\tvalid_1's l1: 19.4711\n",
      "[250]\ttraining's rmse: 23.337\ttraining's l1: 17.9639\tvalid_1's rmse: 23.6617\tvalid_1's l1: 18.1477\n",
      "[300]\ttraining's rmse: 22.172\ttraining's l1: 17.0463\tvalid_1's rmse: 22.5466\tvalid_1's l1: 17.26\n",
      "[350]\ttraining's rmse: 21.3606\ttraining's l1: 16.4175\tvalid_1's rmse: 21.788\tvalid_1's l1: 16.6696\n",
      "[400]\ttraining's rmse: 20.786\ttraining's l1: 15.9747\tvalid_1's rmse: 21.2623\tvalid_1's l1: 16.2651\n",
      "[450]\ttraining's rmse: 20.3701\ttraining's l1: 15.659\tvalid_1's rmse: 20.891\tvalid_1's l1: 15.984\n",
      "[500]\ttraining's rmse: 20.0586\ttraining's l1: 15.4277\tvalid_1's rmse: 20.6265\tvalid_1's l1: 15.7832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\ttraining's rmse: 19.8183\ttraining's l1: 15.2526\tvalid_1's rmse: 20.4276\tvalid_1's l1: 15.6345\n",
      "[600]\ttraining's rmse: 19.627\ttraining's l1: 15.1142\tvalid_1's rmse: 20.2752\tvalid_1's l1: 15.5183\n",
      "[650]\ttraining's rmse: 19.4728\ttraining's l1: 15.0021\tvalid_1's rmse: 20.1566\tvalid_1's l1: 15.4276\n",
      "[700]\ttraining's rmse: 19.338\ttraining's l1: 14.9047\tvalid_1's rmse: 20.0599\tvalid_1's l1: 15.355\n",
      "[750]\ttraining's rmse: 19.2199\ttraining's l1: 14.8199\tvalid_1's rmse: 19.9775\tvalid_1's l1: 15.2938\n",
      "[800]\ttraining's rmse: 19.1176\ttraining's l1: 14.7458\tvalid_1's rmse: 19.9108\tvalid_1's l1: 15.2413\n",
      "[850]\ttraining's rmse: 19.0265\ttraining's l1: 14.6804\tvalid_1's rmse: 19.8557\tvalid_1's l1: 15.1984\n",
      "[900]\ttraining's rmse: 18.9481\ttraining's l1: 14.6242\tvalid_1's rmse: 19.8119\tvalid_1's l1: 15.162\n",
      "[950]\ttraining's rmse: 18.8751\ttraining's l1: 14.5718\tvalid_1's rmse: 19.7725\tvalid_1's l1: 15.1293\n",
      "[1000]\ttraining's rmse: 18.8065\ttraining's l1: 14.5233\tvalid_1's rmse: 19.737\tvalid_1's l1: 15.0988\n",
      "[1050]\ttraining's rmse: 18.7434\ttraining's l1: 14.4785\tvalid_1's rmse: 19.7058\tvalid_1's l1: 15.072\n",
      "[1100]\ttraining's rmse: 18.6832\ttraining's l1: 14.4365\tvalid_1's rmse: 19.6782\tvalid_1's l1: 15.0476\n",
      "[1150]\ttraining's rmse: 18.6279\ttraining's l1: 14.3981\tvalid_1's rmse: 19.6565\tvalid_1's l1: 15.0283\n",
      "[1200]\ttraining's rmse: 18.5742\ttraining's l1: 14.3608\tvalid_1's rmse: 19.636\tvalid_1's l1: 15.0104\n",
      "[1250]\ttraining's rmse: 18.5239\ttraining's l1: 14.3256\tvalid_1's rmse: 19.6162\tvalid_1's l1: 14.9923\n",
      "[1300]\ttraining's rmse: 18.4753\ttraining's l1: 14.2914\tvalid_1's rmse: 19.5985\tvalid_1's l1: 14.9767\n",
      "[1350]\ttraining's rmse: 18.4307\ttraining's l1: 14.2602\tvalid_1's rmse: 19.5842\tvalid_1's l1: 14.9644\n",
      "[1400]\ttraining's rmse: 18.3866\ttraining's l1: 14.2301\tvalid_1's rmse: 19.5708\tvalid_1's l1: 14.9525\n",
      "[1450]\ttraining's rmse: 18.3463\ttraining's l1: 14.2018\tvalid_1's rmse: 19.559\tvalid_1's l1: 14.942\n",
      "[1500]\ttraining's rmse: 18.3055\ttraining's l1: 14.1742\tvalid_1's rmse: 19.5509\tvalid_1's l1: 14.9345\n",
      "[1550]\ttraining's rmse: 18.266\ttraining's l1: 14.1472\tvalid_1's rmse: 19.5412\tvalid_1's l1: 14.9252\n",
      "[1600]\ttraining's rmse: 18.2297\ttraining's l1: 14.1215\tvalid_1's rmse: 19.5331\tvalid_1's l1: 14.9174\n",
      "[1650]\ttraining's rmse: 18.194\ttraining's l1: 14.0967\tvalid_1's rmse: 19.5255\tvalid_1's l1: 14.9099\n",
      "[1700]\ttraining's rmse: 18.1596\ttraining's l1: 14.0729\tvalid_1's rmse: 19.518\tvalid_1's l1: 14.9027\n",
      "[1750]\ttraining's rmse: 18.1249\ttraining's l1: 14.0485\tvalid_1's rmse: 19.5129\tvalid_1's l1: 14.8966\n",
      "[1800]\ttraining's rmse: 18.0914\ttraining's l1: 14.0246\tvalid_1's rmse: 19.5072\tvalid_1's l1: 14.8907\n",
      "[1850]\ttraining's rmse: 18.0582\ttraining's l1: 14.0011\tvalid_1's rmse: 19.5023\tvalid_1's l1: 14.8854\n",
      "[1900]\ttraining's rmse: 18.0279\ttraining's l1: 13.9795\tvalid_1's rmse: 19.4996\tvalid_1's l1: 14.8829\n",
      "[1950]\ttraining's rmse: 17.997\ttraining's l1: 13.958\tvalid_1's rmse: 19.4953\tvalid_1's l1: 14.8788\n",
      "[2000]\ttraining's rmse: 17.9669\ttraining's l1: 13.9371\tvalid_1's rmse: 19.4907\tvalid_1's l1: 14.8741\n",
      "[2050]\ttraining's rmse: 17.9382\ttraining's l1: 13.9168\tvalid_1's rmse: 19.4873\tvalid_1's l1: 14.871\n",
      "[2100]\ttraining's rmse: 17.9095\ttraining's l1: 13.8961\tvalid_1's rmse: 19.4848\tvalid_1's l1: 14.8682\n",
      "[2150]\ttraining's rmse: 17.8811\ttraining's l1: 13.876\tvalid_1's rmse: 19.4823\tvalid_1's l1: 14.8653\n",
      "[2200]\ttraining's rmse: 17.8526\ttraining's l1: 13.8555\tvalid_1's rmse: 19.4799\tvalid_1's l1: 14.8628\n",
      "[2250]\ttraining's rmse: 17.8237\ttraining's l1: 13.8355\tvalid_1's rmse: 19.4773\tvalid_1's l1: 14.86\n",
      "[2300]\ttraining's rmse: 17.7961\ttraining's l1: 13.8155\tvalid_1's rmse: 19.475\tvalid_1's l1: 14.8573\n",
      "[2350]\ttraining's rmse: 17.7671\ttraining's l1: 13.7952\tvalid_1's rmse: 19.4716\tvalid_1's l1: 14.8546\n",
      "[2400]\ttraining's rmse: 17.7393\ttraining's l1: 13.7752\tvalid_1's rmse: 19.4687\tvalid_1's l1: 14.8512\n",
      "[2450]\ttraining's rmse: 17.7128\ttraining's l1: 13.7557\tvalid_1's rmse: 19.4652\tvalid_1's l1: 14.8477\n",
      "[2500]\ttraining's rmse: 17.685\ttraining's l1: 13.7358\tvalid_1's rmse: 19.463\tvalid_1's l1: 14.8452\n",
      "[2550]\ttraining's rmse: 17.6576\ttraining's l1: 13.7165\tvalid_1's rmse: 19.4596\tvalid_1's l1: 14.8414\n",
      "[2600]\ttraining's rmse: 17.6323\ttraining's l1: 13.6975\tvalid_1's rmse: 19.4578\tvalid_1's l1: 14.8399\n",
      "[2650]\ttraining's rmse: 17.6068\ttraining's l1: 13.6786\tvalid_1's rmse: 19.4554\tvalid_1's l1: 14.8368\n",
      "[2700]\ttraining's rmse: 17.5811\ttraining's l1: 13.66\tvalid_1's rmse: 19.4544\tvalid_1's l1: 14.8353\n",
      "[2750]\ttraining's rmse: 17.5551\ttraining's l1: 13.6411\tvalid_1's rmse: 19.4514\tvalid_1's l1: 14.8319\n",
      "[2800]\ttraining's rmse: 17.5296\ttraining's l1: 13.6224\tvalid_1's rmse: 19.4507\tvalid_1's l1: 14.8305\n",
      "[2850]\ttraining's rmse: 17.5046\ttraining's l1: 13.6043\tvalid_1's rmse: 19.4489\tvalid_1's l1: 14.8285\n",
      "[2900]\ttraining's rmse: 17.4793\ttraining's l1: 13.5863\tvalid_1's rmse: 19.4464\tvalid_1's l1: 14.826\n",
      "[2950]\ttraining's rmse: 17.454\ttraining's l1: 13.5677\tvalid_1's rmse: 19.4446\tvalid_1's l1: 14.8237\n",
      "[3000]\ttraining's rmse: 17.4292\ttraining's l1: 13.5496\tvalid_1's rmse: 19.443\tvalid_1's l1: 14.8218\n",
      "[3050]\ttraining's rmse: 17.4062\ttraining's l1: 13.5326\tvalid_1's rmse: 19.4406\tvalid_1's l1: 14.8195\n",
      "[3100]\ttraining's rmse: 17.3818\ttraining's l1: 13.5152\tvalid_1's rmse: 19.4402\tvalid_1's l1: 14.8184\n",
      "[3150]\ttraining's rmse: 17.3581\ttraining's l1: 13.498\tvalid_1's rmse: 19.4392\tvalid_1's l1: 14.8168\n",
      "[3200]\ttraining's rmse: 17.3344\ttraining's l1: 13.4804\tvalid_1's rmse: 19.4377\tvalid_1's l1: 14.8152\n",
      "[3250]\ttraining's rmse: 17.3116\ttraining's l1: 13.4637\tvalid_1's rmse: 19.438\tvalid_1's l1: 14.8142\n",
      "[3300]\ttraining's rmse: 17.2893\ttraining's l1: 13.4468\tvalid_1's rmse: 19.4375\tvalid_1's l1: 14.8134\n",
      "[3350]\ttraining's rmse: 17.2652\ttraining's l1: 13.4296\tvalid_1's rmse: 19.4356\tvalid_1's l1: 14.8116\n",
      "[3400]\ttraining's rmse: 17.2432\ttraining's l1: 13.4131\tvalid_1's rmse: 19.4353\tvalid_1's l1: 14.811\n",
      "[3450]\ttraining's rmse: 17.2203\ttraining's l1: 13.3963\tvalid_1's rmse: 19.4353\tvalid_1's l1: 14.8105\n",
      "[3500]\ttraining's rmse: 17.1977\ttraining's l1: 13.3793\tvalid_1's rmse: 19.4347\tvalid_1's l1: 14.81\n",
      "[3550]\ttraining's rmse: 17.1746\ttraining's l1: 13.3621\tvalid_1's rmse: 19.4334\tvalid_1's l1: 14.8091\n",
      "[3600]\ttraining's rmse: 17.1516\ttraining's l1: 13.3453\tvalid_1's rmse: 19.4329\tvalid_1's l1: 14.8085\n",
      "[3650]\ttraining's rmse: 17.1294\ttraining's l1: 13.3288\tvalid_1's rmse: 19.4321\tvalid_1's l1: 14.8075\n",
      "[3700]\ttraining's rmse: 17.1068\ttraining's l1: 13.312\tvalid_1's rmse: 19.4324\tvalid_1's l1: 14.8071\n",
      "[3750]\ttraining's rmse: 17.0844\ttraining's l1: 13.2959\tvalid_1's rmse: 19.4323\tvalid_1's l1: 14.8063\n",
      "[3800]\ttraining's rmse: 17.0629\ttraining's l1: 13.2798\tvalid_1's rmse: 19.4323\tvalid_1's l1: 14.8059\n",
      "[3850]\ttraining's rmse: 17.0405\ttraining's l1: 13.2633\tvalid_1's rmse: 19.4323\tvalid_1's l1: 14.8052\n",
      "[3900]\ttraining's rmse: 17.0187\ttraining's l1: 13.2471\tvalid_1's rmse: 19.4318\tvalid_1's l1: 14.8048\n",
      "[3950]\ttraining's rmse: 16.9968\ttraining's l1: 13.2307\tvalid_1's rmse: 19.4318\tvalid_1's l1: 14.8042\n",
      "[4000]\ttraining's rmse: 16.9756\ttraining's l1: 13.2149\tvalid_1's rmse: 19.432\tvalid_1's l1: 14.804\n",
      "[4050]\ttraining's rmse: 16.9547\ttraining's l1: 13.1991\tvalid_1's rmse: 19.4314\tvalid_1's l1: 14.8028\n",
      "[4100]\ttraining's rmse: 16.9332\ttraining's l1: 13.1827\tvalid_1's rmse: 19.4304\tvalid_1's l1: 14.8023\n",
      "[4150]\ttraining's rmse: 16.9109\ttraining's l1: 13.1666\tvalid_1's rmse: 19.4297\tvalid_1's l1: 14.8019\n",
      "[4200]\ttraining's rmse: 16.8894\ttraining's l1: 13.1507\tvalid_1's rmse: 19.4292\tvalid_1's l1: 14.8009\n",
      "[4250]\ttraining's rmse: 16.8682\ttraining's l1: 13.1349\tvalid_1's rmse: 19.43\tvalid_1's l1: 14.8009\n",
      "[4300]\ttraining's rmse: 16.8467\ttraining's l1: 13.1194\tvalid_1's rmse: 19.4291\tvalid_1's l1: 14.8\n",
      "[4350]\ttraining's rmse: 16.8259\ttraining's l1: 13.1037\tvalid_1's rmse: 19.4302\tvalid_1's l1: 14.8004\n",
      "[4400]\ttraining's rmse: 16.8058\ttraining's l1: 13.0883\tvalid_1's rmse: 19.4303\tvalid_1's l1: 14.8003\n",
      "[4450]\ttraining's rmse: 16.7855\ttraining's l1: 13.0728\tvalid_1's rmse: 19.431\tvalid_1's l1: 14.8005\n",
      "[4500]\ttraining's rmse: 16.7644\ttraining's l1: 13.0572\tvalid_1's rmse: 19.4306\tvalid_1's l1: 14.8002\n",
      "Early stopping, best iteration is:\n",
      "[4280]\ttraining's rmse: 16.8555\ttraining's l1: 13.1257\tvalid_1's rmse: 19.4289\tvalid_1's l1: 14.7999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "MAE Model 0.06314368002017899\n",
      "MSE Model 0.06329154300724835\n",
      "Merge Model12 0.06328324083589802\n",
      "[LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1,\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective='mae', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1,\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective='mae', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1,\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective='mae', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1,\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective='mae', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1,\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective='mae', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1)]\n",
      "[LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1, metric='rmse',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective=None, random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1, metric='rmse',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective=None, random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1, metric='rmse',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective=None, random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1, metric='rmse',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective=None, random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1), LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
      "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "       colsample_bytree=1.0, feature_fraction=0.9, importance_type='split',\n",
      "       lambda_l1=0.1, learning_rate=0.005, max_depth=-1, metric='rmse',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=32,\n",
      "       min_split_gain=0.0, n_estimators=10000, n_jobs=-1, nthread=50,\n",
      "       num_leaves=31, objective=None, random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1)]\n",
      "              feature   gain  fold\n",
      "0         用户实名制是否通过核实     27     1\n",
      "1                用户年龄  13369     1\n",
      "2             是否大学生客户     92     1\n",
      "3             是否黑名单客户    166     1\n",
      "4           是否4G不健康客户    607     1\n",
      "5             用户网龄（月）  10832     1\n",
      "6     用户最近一次缴费距今时长（月）    431     1\n",
      "7     缴费用户最近一次缴费金额（元）   4839     1\n",
      "8      用户近6个月平均消费值（元）  13747     1\n",
      "9        用户账单当月总费用（元）  12051     1\n",
      "10        用户当月账户余额（元）   6224     1\n",
      "11       缴费用户当前是否欠费缴费    537     1\n",
      "12            用户话费敏感度   3828     1\n",
      "13          当月通话交往圈人数  12374     1\n",
      "14          是否经常逛商场的人    488     1\n",
      "15       近三个月月均商场出现次数   8550     1\n",
      "16       当月是否逛过福州仓山万达    314     1\n",
      "17      当月是否到过福州山姆会员店    188     1\n",
      "18            当月是否看电影    942     1\n",
      "19           当月是否景点游览    944     1\n",
      "20         当月是否体育场馆消费    890     1\n",
      "21        当月网购类应用使用次数   9963     1\n",
      "22      当月物流快递类应用使用次数    499     1\n",
      "23     当月金融理财类应用使用总次数   8481     1\n",
      "24      当月视频播放类应用使用次数   9374     1\n",
      "25        当月飞机类应用使用次数    525     1\n",
      "26        当月火车类应用使用次数   1213     1\n",
      "27      当月旅游资讯类应用使用次数   4909     1\n",
      "28                 次数   8954     1\n",
      "29  当月金融理财类应用使用总次数百分比   9247     1\n",
      "..                ...    ...   ...\n",
      "6     用户最近一次缴费距今时长（月）    552     5\n",
      "7     缴费用户最近一次缴费金额（元）   5505     5\n",
      "8      用户近6个月平均消费值（元）  14831     5\n",
      "9        用户账单当月总费用（元）  13662     5\n",
      "10        用户当月账户余额（元）   7458     5\n",
      "11       缴费用户当前是否欠费缴费    599     5\n",
      "12            用户话费敏感度   4438     5\n",
      "13          当月通话交往圈人数  14602     5\n",
      "14          是否经常逛商场的人    626     5\n",
      "15       近三个月月均商场出现次数  10188     5\n",
      "16       当月是否逛过福州仓山万达    163     5\n",
      "17      当月是否到过福州山姆会员店    324     5\n",
      "18            当月是否看电影    886     5\n",
      "19           当月是否景点游览   1020     5\n",
      "20         当月是否体育场馆消费   1189     5\n",
      "21        当月网购类应用使用次数  12132     5\n",
      "22      当月物流快递类应用使用次数    733     5\n",
      "23     当月金融理财类应用使用总次数  10357     5\n",
      "24      当月视频播放类应用使用次数  11303     5\n",
      "25        当月飞机类应用使用次数    586     5\n",
      "26        当月火车类应用使用次数   1330     5\n",
      "27      当月旅游资讯类应用使用次数   5562     5\n",
      "28                 次数   9953     5\n",
      "29  当月金融理财类应用使用总次数百分比  11479     5\n",
      "30   当月旅游资讯类应用使用次数百分比   6821     5\n",
      "31           当月通话人均话费  12576     5\n",
      "32              上个月费用  11583     5\n",
      "33             用户上网年龄   8759     5\n",
      "34          用户上网年龄百分比   9679     5\n",
      "35              近似总消费  12310     5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_mae, models_mse, importances   = _get_values_lgbregresser_models(train_fea[fea_cols].values, train_fea['信用分'].values, feature_names=fea_cols)\n",
    "#print(models_mae)\n",
    "#print(models_mse)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE提交（0.06354）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mae = 0\n",
    "for i,model in enumerate(models_mae): \n",
    "    pred_mae += model.predict(test_fea[fea_cols]) * 0.2\n",
    "test_fea['pred_mae'] = pred_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mse = 0\n",
    "for i,model in enumerate(models_mse): \n",
    "    pred_mse += model.predict(test_fea[fea_cols]) * 0.2\n",
    "test_fea['pred_mse'] = pred_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.00000\n",
       "mean       618.78192\n",
       "std         37.69697\n",
       "min        477.00000\n",
       "25%        598.00000\n",
       "50%        628.00000\n",
       "75%        646.00000\n",
       "max        695.00000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_mae = pd.DataFrame()\n",
    "submit_mae['id']    = test_fea['用户编码'].values\n",
    "submit_mae['score'] = test_fea['pred_mae'].values \n",
    "submit_mae['score'] = submit_mae['score'].astype(int)\n",
    "submit_mae[['id','score']].to_csv('baseline_mae.csv',index = None)\n",
    "submit_mae['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7171737d49b143d1b38883a39e4a5730</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3af0a449d5424488912e8fb2bf4b9faa</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb2cf02e0d5c4d1294dd73e776dbb441</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9c0f780ecb254670a11aa9e3f10777c5</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d794eed46c1e44f785a575f18b3023a5</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  score\n",
       "0  7171737d49b143d1b38883a39e4a5730    602\n",
       "1  3af0a449d5424488912e8fb2bf4b9faa    538\n",
       "2  eb2cf02e0d5c4d1294dd73e776dbb441    669\n",
       "3  9c0f780ecb254670a11aa9e3f10777c5    672\n",
       "4  d794eed46c1e44f785a575f18b3023a5    654"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_mae.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE+MSE提交（0.06359）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fea = test_fea.sort_values('pred_mae')\n",
    "test_fea['ranks'] = list(range(test_fea.shape[0]))\n",
    "test_fea['score'] = test_fea['pred_mae'].values\n",
    "test_fea.loc[test_fea.ranks<10000,'score']  = test_fea.loc[test_fea.ranks< 10000,'pred_mse'].values *0.4 + test_fea.loc[test_fea.ranks< 10000,'pred_mae'].values * 0.6\n",
    "test_fea.loc[test_fea.ranks>40000,'score']  = test_fea.loc[test_fea.ranks> 40000,'pred_mse'].values *0.4 + test_fea.loc[test_fea.ranks> 40000,'pred_mae'].values * 0.6         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       618.588620\n",
       "std         37.867445\n",
       "min        472.000000\n",
       "25%        598.000000\n",
       "50%        628.000000\n",
       "75%        646.000000\n",
       "max        694.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_mae_mse = pd.DataFrame()\n",
    "submit_mae_mse['id']    = test_fea['用户编码'].values\n",
    "submit_mae_mse['score'] = test_fea['score'].values \n",
    "submit_mae_mse['score'] = submit_mae_mse['score'].astype(int)\n",
    "submit_mae_mse[['id','score']].to_csv('baseline_mae_mse.csv',index = None)\n",
    "submit_mae_mse['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398144a5d5b7419ca6b6b192932a2108</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c6b41b5d514bbdaa6d1a5d6347ad0b</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45743e0591c84958b9f0ac714707f634</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e844f800971a4f48aa2fb4cd6cf4fb1a</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6501a59bee344417b115236ceca75c36</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  score\n",
       "0  398144a5d5b7419ca6b6b192932a2108    472\n",
       "1  15c6b41b5d514bbdaa6d1a5d6347ad0b    478\n",
       "2  45743e0591c84958b9f0ac714707f634    478\n",
       "3  e844f800971a4f48aa2fb4cd6cf4fb1a    482\n",
       "4  6501a59bee344417b115236ceca75c36    483"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_mae_mse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
